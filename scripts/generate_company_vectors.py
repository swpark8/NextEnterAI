"""
company_50_pool.jsonì„ ê¸°ë°˜ìœ¼ë¡œ company_jd_vectors.pkl íŒŒì¼ì„ ìƒì„±í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
jhgan/ko-sroberta-multitask ëª¨ë¸ë¡œ 768ì°¨ì› ë²¡í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""
import os
import json
import pickle
import numpy as np
from pathlib import Path
from datetime import datetime

try:
    from sentence_transformers import SentenceTransformer
except ImportError:
    print("âŒ sentence_transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("pip install sentence-transformers ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
    exit(1)


def create_text_from_company(company):
    """
    ê¸°ì—… ì •ë³´ë¥¼ ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    
    Args:
        company: company_50_pool.jsonì˜ ê¸°ì—… ê°ì²´
    
    Returns:
        str: ì„ë² ë”©ìš© í…ìŠ¤íŠ¸
    """
    parts = []
    
    # ê¸°ì—…ëª…
    if company.get('name'):
        parts.append(company['name'])
    
    # ì‚°ì—…
    if company.get('industry'):
        parts.append(company['industry'])
    
    # ê¸°ìˆ  ìŠ¤íƒ
    if company.get('tech_stack'):
        parts.append(" ".join(company['tech_stack']))
    
    # ì§ë¬´
    if company.get('target_roles'):
        parts.append(" ".join(company['target_roles']))
    
    # ìœ„ì¹˜ (ì„ íƒì )
    if company.get('location'):
        parts.append(company['location'])
    
    return " ".join(parts)


def generate_company_vectors():
    """
    company_50_pool.jsonì„ ì½ì–´ì„œ company_jd_vectors.pkl íŒŒì¼ì„ ìƒì„±
    """
    # ê²½ë¡œ ì„¤ì •
    base_dir = Path(__file__).parent.parent
    data_dir = base_dir / "app" / "data"
    input_path = data_dir / "company_50_pool.json"
    output_path = data_dir / "company_jd_vectors.pkl"
    
    # ì…ë ¥ íŒŒì¼ í™•ì¸
    if not input_path.exists():
        print(f"âŒ ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_path}")
        return False
    
    # ê¸°ì¡´ íŒŒì¼ ë°±ì—…
    if output_path.exists():
        print(f"ğŸ“¦ ê¸°ì¡´ ë²¡í„° íŒŒì¼ ë°±ì—… ì¤‘: {backup_path}")
        import shutil
        shutil.copy2(output_path, backup_path)
        print(f"âœ… ë°±ì—… ì™„ë£Œ: {backup_path}")
    
    # JSON íŒŒì¼ ë¡œë“œ
    print(f"ğŸ“‚ ê¸°ì—… ë°ì´í„° ë¡œë“œ ì¤‘: {input_path}")
    with open(input_path, 'r', encoding='utf-8') as f:
        companies = json.load(f)
    
    print(f"âœ… ê¸°ì—… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(companies)}ê°œ ê¸°ì—…")
    
    # ëª¨ë¸ ë¡œë“œ
    model_name = "jhgan/ko-sroberta-multitask"
    print(f"\nğŸ§  ëª¨ë¸ ë¡œë“œ ì¤‘: {model_name}")
    print("   (ì²« ì‹¤í–‰ ì‹œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œì— ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤...)")
    model = SentenceTransformer(model_name)
    print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ì¶œë ¥ ì°¨ì›: {model.get_sentence_embedding_dimension()}ì°¨ì›)")
    
    # í…ìŠ¤íŠ¸ ìƒì„± ë° ì„ë² ë”©
    print(f"\nğŸ”„ ë²¡í„° ìƒì„± ì¤‘... ({len(companies)}ê°œ ê¸°ì—…)")
    texts = []
    for i, company in enumerate(companies):
        text = create_text_from_company(company)
        texts.append(text)
        
        if (i + 1) % 10 == 0:
            print(f"   ì§„í–‰ ì¤‘: {i + 1}/{len(companies)}")
    
    # ë°°ì¹˜ ì„ë² ë”© ìƒì„±
    print(f"\nğŸš€ ì„ë² ë”© ìƒì„± ì¤‘...")
    vectors = model.encode(texts, show_progress_bar=True, batch_size=32)
    
    # ê²°ê³¼ í™•ì¸
    print(f"\nâœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ")
    print(f"   ë²¡í„° shape: {vectors.shape}")
    print(f"   ì˜ˆìƒ ì°¨ì›: 768ì°¨ì›")
    
    # pickle íŒŒì¼ë¡œ ì €ì¥
    print(f"\nğŸ’¾ ë²¡í„° íŒŒì¼ ì €ì¥ ì¤‘: {output_path}")
    output_data = {
        'companies': companies,
        'vectors': vectors
    }
    
    with open(output_path, 'wb') as f:
        pickle.dump(output_data, f)
    
    print(f"âœ… ì €ì¥ ì™„ë£Œ!")
    
    # ê²€ì¦
    print(f"\nğŸ” ê²€ì¦ ì¤‘...")
    with open(output_path, 'rb') as f:
        loaded_data = pickle.load(f)
    
    print(f"   ì €ì¥ëœ ê¸°ì—… ìˆ˜: {len(loaded_data['companies'])}")
    print(f"   ì €ì¥ëœ ë²¡í„° shape: {loaded_data['vectors'].shape}")
    print(f"   ë°ì´í„° íƒ€ì…: {loaded_data['vectors'].dtype}")
    print(f"   ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {loaded_data['vectors'].nbytes / 1024 / 1024:.2f} MB")
    
    # êµ¬ì¡° ê²€ì¦
    if not isinstance(loaded_data, dict):
        print(f"âŒ ì˜¤ë¥˜: ì €ì¥ëœ ë°ì´í„°ê°€ dict í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
        return False
    
    if 'companies' not in loaded_data or 'vectors' not in loaded_data:
        print(f"âŒ ì˜¤ë¥˜: ì €ì¥ëœ ë°ì´í„°ì— 'companies' ë˜ëŠ” 'vectors' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    if len(loaded_data['companies']) != loaded_data['vectors'].shape[0]:
        print(f"âŒ ì˜¤ë¥˜: ê¸°ì—… ìˆ˜({len(loaded_data['companies'])})ì™€ ë²¡í„° ìˆ˜({loaded_data['vectors'].shape[0]})ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return False
    
    if loaded_data['vectors'].shape[1] != 768:
        print(f"âš ï¸  ê²½ê³ : ì˜ˆìƒê³¼ ë‹¤ë¥¸ ì°¨ì›ì…ë‹ˆë‹¤. ({loaded_data['vectors'].shape[1]}ì°¨ì›, ì˜ˆìƒ: 768ì°¨ì›)")
        return False
    
    print(f"âœ… 768ì°¨ì› ë²¡í„°ê°€ ì •ìƒì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
    print(f"âœ… ê¸°ì—… ìˆ˜: {len(loaded_data['companies'])}ê°œ")
    
    return True


if __name__ == "__main__":
    print("=" * 60)
    print("company_50_pool.json â†’ company_jd_vectors.pkl ìƒì„± ìŠ¤í¬ë¦½íŠ¸")
    print("=" * 60)
    print()
    
    success = generate_company_vectors()
    
    print()
    print("=" * 60)
    if success:
        print("âœ… ë²¡í„° íŒŒì¼ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("âœ… AI ì„œë²„ë¥¼ ì¬ì‹œì‘í•˜ë©´ ìƒˆë¡œìš´ ë²¡í„° íŒŒì¼ì´ ì ìš©ë©ë‹ˆë‹¤.")
    else:
        print("âŒ ë²¡í„° íŒŒì¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    print("=" * 60)
