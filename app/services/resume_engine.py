import json
import re
import os
import pickle
import numpy as np
from typing import List, Dict, Optional
from pathlib import Path

# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ
try:
    from sentence_transformers import SentenceTransformer
    from sklearn.metrics.pairwise import cosine_similarity
    from openai import OpenAI
except ImportError as e:
    print(f"âš ï¸ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")
    # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ë¡œê·¸ë¥¼ ë‚¨ê¸°ê±°ë‚˜ ì—ëŸ¬ë¥¼ raise í•  ìˆ˜ ìˆìŒ

# ==========================================
# 1. ë°ì´í„° ë¡œë“œ ë° ê²½ë¡œ ì„¤ì •
# ==========================================
def get_project_root() -> Path:
    """
    í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    app/services/resume_validation_engine.py -> í”„ë¡œì íŠ¸ ë£¨íŠ¸
    """
    current_file = Path(__file__).resolve()
    return current_file.parent.parent.parent

def get_data_path() -> Path:
    """
    ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    return get_project_root() / "app" / "data"

class DataLoader:
    """
    ê¸°ì¡´ ë°ì´í„° ë¡œë” ìœ ì§€ (í•„ìš” ì‹œ ë‹¤ë¥¸ ë©”íƒ€ë°ì´í„° ì ‘ê·¼ìš©)
    """
    def __init__(self):
        self.base_path = get_data_path()
        self.file_names = {
            "resumes": "final_resume_600.json",
            "companies": "company_50_pool.json",
            "metadata": "final_metadata_600.json"
        }
        self.data = {}
        # í•„ìš”í•˜ë‹¤ë©´ ì—¬ê¸°ì„œ íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ìˆìŒ. 
        # í˜„ì¬ MatchingEngineì€ pickle íŒŒì¼ì„ ì§ì ‘ ë¡œë“œí•˜ë¯€ë¡œ,
        # ì—¬ê¸°ì„œëŠ” ê²½ë¡œ í™•ì¸ ì •ë„ë§Œ ìˆ˜í–‰í•˜ê±°ë‚˜ ë¹„ì›Œë‘˜ ìˆ˜ ìˆìŒ.
        
    def normalize(self, text):
        if not text: return ""
        return re.sub(r'[^a-zA-Z0-9]', '', str(text).lower())

# ==========================================
# 2. ë§¤ì¹­ ì—”ì§„ (Hybrid Vector + Keyword)
# ==========================================
class MatchingEngine:
    """
    [Core Engine]
    í•˜ì´ë¸Œë¦¬ë“œ ë§¤ì¹­ (ë²¡í„° 55% + í‚¤ì›Œë“œ 35%) + [Metadata Bonus 10%]
    + [Smart Calibration] (ëœë¤ì´ ì•„ë‹Œ, ì‹¤ë ¥ ê¸°ë°˜ ì ìˆ˜ ë§¤í•‘)
    """

    # 1. ë§¤ì¹­ ê°€ì¤‘ì¹˜ (Total 1.0)
    WEIGHT_VECTOR = 0.55
    WEIGHT_KEYWORD = 0.35
    BONUS_ROLE_MATCH = 0.10

    # 2. ë“±ê¸‰ë³„ ì¶”ì²œ ê¸°ì—… í‹°ì–´ (Quota)
    TIER_RULES = {
        "S": ["Top", "Top", "Mid"],
        "A": ["Top", "Mid", "Mid"],
        "B": ["Mid", "Mid", "Low"],
        "C": ["Mid", "Low", "Low"],
        "F": ["Low", "Low", "Low"]
    }

    # 3. ëª©í‘œ ì ìˆ˜ êµ¬ê°„ (ì‚¬ìš©ì ë§Œì¡±ìš©)
    SCORE_RANGES = [
        (88.0, 97.0), # Rank 1
        (77.0, 86.0), # Rank 2
        (66.0, 75.0)  # Rank 3
    ]

    # [NEW] í˜„ì‹¤ì ì¸ Raw Score ê¸°ì¤€ì  (ì •ê·œí™” í›„ ê¸°ì¤€)
    RAW_SCORE_MIN = 0.30
    RAW_SCORE_MAX = 0.95
    GAP_THRESHOLD = 0.50  # 0.5ì (50ì ) ë¯¸ë§Œì´ë©´ ê²½ê³ 

    def __init__(self):
        print("ğŸš€ ë§¤ì¹­ ì—”ì§„(Matching Engine) ì´ˆê¸°í™” ì¤‘...")
        
        self.base_path = get_data_path()
        self.model_name = "jhgan/ko-sroberta-multitask"
        
        # OpenAI Client (í™˜ê²½ë³€ìˆ˜ì—ì„œ í‚¤ ë¡œë“œ)
        api_key = os.environ.get("OPENAI_API_KEY")
        self.client = OpenAI(api_key=api_key) if api_key else None

        # Model Load
        print(f"   -> ëª¨ë¸ ë¡œë“œ ì¤‘: {self.model_name}")
        # ëª¨ë¸ ë¡œë”©ì€ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œëŠ” ì‹±ê¸€í†¤ íŒ¨í„´ì´ë‚˜ ì‹œì‘ ì‹œ ë¡œë“œë¥¼ ê³ ë ¤í•´ì•¼ í•¨
        # ì—¬ê¸°ì„œëŠ” ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹œ ë¡œë“œ
        self.model = SentenceTransformer(self.model_name)

        # Data Load
        self.company_data = self._load_company_vectors()
        
        # DataLoader ì¸ìŠ¤í„´ìŠ¤ (ë³´ì¡°ìš©)
        self.dl = DataLoader()

    def _load_company_vectors(self):
        """pkl íŒŒì¼ ë¡œë“œ"""
        pkl_path = self.base_path / "company_jd_vectors.pkl"
        
        if not pkl_path.exists():
            print(f"âŒ ê¸°ì—… ë²¡í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pkl_path}")
            return None
            
        try:
            with open(pkl_path, 'rb') as f:
                data = pickle.load(f)
            if isinstance(data, dict) and 'vectors' in data:
                print(f"   -> ê¸°ì—… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(data['companies'])}ê°œ ê¸°ì—…")
                return data
            else:
                print("âŒ pkl íŒŒì¼ êµ¬ì¡° ì˜¤ë¥˜")
                return None
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {e}")
            return None

    def _calculate_keyword_score(self, resume_text: str, tech_stack: List[str]) -> float:
        if not tech_stack: return 0.5
        resume_lower = resume_text.lower()
        match_count = sum(1 for t in tech_stack if t.lower() in resume_lower)
        return match_count / len(tech_stack)

    def _calculate_metadata_bonus(self, candidate_role: str, company_target_roles: List[str]) -> float:
        if not candidate_role or not company_target_roles: return 0.0
        cand_role_lower = candidate_role.lower()
        
        for role in company_target_roles:
            role_lower = role.lower()
            # 1. ì™„ì „ ì¼ì¹˜ ë˜ëŠ” í¬í•¨ ê´€ê³„
            if role_lower in cand_role_lower or cand_role_lower in role_lower:
                return self.BONUS_ROLE_MATCH
            
            # 2. Fullstack ìœ ì—°í•œ ë§¤ì¹­ (FE/BE ëª¨ë‘ ì¸ì •)
            if "fullstack" in cand_role_lower and (role_lower in ["backend", "frontend"]):
                return self.BONUS_ROLE_MATCH * 0.8
            
            # 3. AI/LLM Engineer íŠ¹í™” ë§¤ì¹­
            if "ai" in cand_role_lower or "llm" in cand_role_lower:
                if any(kw in role_lower for kw in ["nlp", "llm", "vision", "ai", "ml", "data"]):
                    return self.BONUS_ROLE_MATCH
            
            # 4. UI/UX Designer íŠ¹í™” ë§¤ì¹­
            if "ui/ux" in cand_role_lower or "designer" in cand_role_lower:
                if any(kw in role_lower for kw in ["design", "ui", "ux", "product", "creative"]):
                    return self.BONUS_ROLE_MATCH
                    
        return 0.0

    def _check_role_relevance(self, target_category: str, current_role: str) -> bool:
        """
        [Team Rule] ì§€ì› ì§ë¬´ì™€ ì´ì „ ê²½ë ¥ ì§ë¬´ ê°„ì˜ ìœ ì‚¬ì„± íŒë‹¨
        """
        if not target_category or not current_role: return False
        target_category = target_category.lower()
        current_role = current_role.lower()
        
        # ê¸°ë³¸ í‚¤ì›Œë“œ ì •ì˜
        relevance_keywords = [target_category, 'ê¸°íš', 'ê°œë°œ', 'developer', 'manager', 'engineer', 'design']
        
        # ì‹ ê·œ ì§ë¬´ë³„ í™•ì¥ í‚¤ì›Œë“œ
        if "designer" in target_category or "ui/ux" in target_category:
            relevance_keywords.extend(['art', 'creative', 'ux', 'ui', 'ë””ìì¸', 'ë””ìì´ë„ˆ', 'í¼ë¸”ë¦¬ì…”'])
        
        if "ai" in target_category or "llm" in target_category:
            relevance_keywords.extend(['researcher', 'scientist', 'nlp', 'ml', 'data', 'lab', 'ì—°êµ¬ì›'])
        
        if any(kw in current_role for kw in relevance_keywords):
            return True
        return False

    def _normalize_vector_score(self, val: float) -> float:
        """
        [New] S-BERT Cosine Similarity ì •ê·œí™”
        ê¸°ê³„ì  ìœ ì‚¬ë„(0.15~0.75)ë¥¼ ì¸ê°„ì´ ì´í•´í•˜ëŠ” ì ìˆ˜(0.0~1.0)ë¡œ ë³€í™˜
        """
        min_bound = 0.15
        max_bound = 0.75

        normalized = (val - min_bound) / (max_bound - min_bound)
        return max(0.0, min(1.0, normalized))

    def get_grade(self, score: float) -> str:
        """ì ìˆ˜ ê¸°ë°˜ ë“±ê¸‰ íŒì •"""
        if score >= 90: return "S"
        if score >= 80: return "A"
        if score >= 70: return "B"
        if score >= 60: return "C"
        return "F"

    def verify_and_regrade(self, resume_input: dict, final_raw_score: float) -> float:
        """
        [Ghost F í•´ê²°] í…ìŠ¤íŠ¸ ë§¤ì¹­ì€ ì¤€ìˆ˜í•˜ë‚˜ ì ìˆ˜ê°€ ë‚®ê²Œ ë‚˜ì˜¨ ê²½ìš° ë³´ì •
        ê²½ë ¥(40%), í”„ë¡œì íŠ¸(30%), ê¸°ìˆ (20%), í•™ë ¥(10%) ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì •ë°€ ì¬ì±„ì 
        """
        content = resume_input.get('resume_content', {})
        
        # 1. í•™ë ¥ ì ìˆ˜ (10%)
        edu_score = 0.0
        for edu in content.get('education', []):
            major = edu.get('major', '').lower()
            if any(kw in major for kw in ['ì»´í“¨í„°', 'computer', 'ì†Œí”„íŠ¸ì›¨ì–´', 'software', 'IT', 'ì „ì‚°']):
                edu_score = 0.1
                break
        
        # 2. ê²½ë ¥ ì ìˆ˜ (40%)
        exp_score = 0.0
        experiences = content.get('professional_experience', [])
        if experiences:
            exp_score = 0.2 # ê¸°ë³¸ ê²½ë ¥ ë³´ìœ 
            for exp in experiences:
                period = str(exp.get('period', ''))
                # 3ë…„ ì´ìƒ ê²½ë ¥ ì‹œ ê°€ì¤‘ì¹˜ ìµœëŒ€
                if any(kw in period for kw in ['36ê°œì›”', '3ë…„', '48ê°œì›”', '4ë…„', '5ë…„', '60ê°œì›”']):
                    exp_score = 0.4
                    break
        
        # 3. í”„ë¡œì íŠ¸ ì ìˆ˜ (30%)
        proj_score = 0.0
        if content.get('project_experience', []):
            proj_score = 0.3

        # 4. ê¸°ìˆ  ì ìˆ˜ (ê¸°ì¡´ final_raw_score í™œìš© - 20%)
        tech_score = final_raw_score * 0.2

        # ìµœì¢… ë³´ì • ì ìˆ˜
        refined_score = tech_score + exp_score + proj_score + edu_score
        
        # [Ghost F ë°©ì–´] í•™ë ¥ê³¼ ê²½ë ¥ì´ ì–‘í˜¸í•˜ë©´ ìµœì†Œ Cë“±ê¸‰(0.6) í•˜í•œì„  ë³´ì¥
        if (edu_score >= 0.1 or exp_score >= 0.3) and refined_score < 0.6:
            refined_score = 0.6
            
        return min(1.0, refined_score)

    def _map_score_to_range(self, raw_score: float, target_min: float, target_max: float) -> float:
        """
        [Dynamic Scaling] í˜„ì‹¤ì ì¸ ì…ë ¥ ë²”ìœ„(Raw Score)ë¥¼ ëª©í‘œ ë²”ìœ„ë¡œ ë§¤í•‘
        """
        input_min, input_max = self.RAW_SCORE_MIN, self.RAW_SCORE_MAX

        normalized = (raw_score - input_min) / (input_max - input_min)
        normalized = max(0.0, min(1.0, normalized))

        scaled_score = target_min + (normalized * (target_max - target_min))
        return round(scaled_score, 1)

    def _categorize_companies(self, all_companies, vector_scores, resume_input, candidate_role):
        buckets = {"Top": [], "Mid": [], "Low": []}
        resume_text = self._convert_resume_to_text(resume_input)
        
        # 0. ì´ë ¥ì„œ ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ (Fë“±ê¸‰ íŒì •ìš©)
        content = resume_input.get('resume_content', {})
        experiences = content.get('professional_experience', [])
        
        # ê²½ë ¥ ì›”ìˆ˜ ì¶”ì¶œ
        actual_months = 0
        current_exp_role = ""
        if experiences:
            period_str = str(experiences[0].get('period', '0'))
            current_exp_role = experiences[0].get('role', '')
            nums = re.findall(r'\d+', period_str)
            actual_months = int(nums[0]) if nums else 0
            
        # ì§ë¬´ ê´€ë ¨ì„± ì²´í¬
        is_relevant_role = self._check_role_relevance(candidate_role, current_exp_role)

        for idx, comp in enumerate(all_companies):
            # 1. ë²¡í„° ì ìˆ˜ ì •ê·œí™”
            v_raw = float(vector_scores[idx])
            v_norm = self._normalize_vector_score(v_raw)

            # 2. í‚¤ì›Œë“œ ì ìˆ˜
            k_score = self._calculate_keyword_score(resume_text, comp.get('tech_stack', []))

            # Semantic Rescue (í‚¤ì›Œë“œ 0ì  êµ¬ì œ)
            if k_score == 0.0 and v_norm > 0.5: k_score = 0.2

            # 3. ê°€ì¤‘ì¹˜ ì ìš© í•©ì‚°
            hybrid_score = (v_norm * self.WEIGHT_VECTOR) + (k_score * self.WEIGHT_KEYWORD)

            # 4. ë©”íƒ€ë°ì´í„° ë³´ë„ˆìŠ¤
            meta_bonus = self._calculate_metadata_bonus(candidate_role, comp.get('target_roles', []))

            base_hybrid_score = hybrid_score + meta_bonus
            
            # [ì¶”ê°€] ì§ë¬´ ë¶ˆì¼ì¹˜ ê°ì  (Conflict Penalty)
            # ë©”íƒ€ë°ì´í„° ë³´ë„ˆìŠ¤ê°€ 0ì¸ë° ë²¡í„° ì ìˆ˜ë§Œ ë†’ì€ ê²½ìš°, ì‹¤ì œ ì§ë¬´ê°€ ë‹¤ë¥¼ í™•ë¥ ì´ ë†’ìœ¼ë¯€ë¡œ ê°ì 
            if meta_bonus == 0 and v_norm > 0.4:
                base_hybrid_score -= 0.15 # ì•½ 15ì  ê°ì 
            
            # 5. [Ghost F í•´ê²°] ì •ë°€ ì¬ì±„ì  (í•™ë ¥/ê²½ë ¥ ê°€ì¤‘ì¹˜ ë°˜ì˜)
            final_raw_score = self.verify_and_regrade(resume_input, base_hybrid_score)

            # 6. [Team Rule] Fë“±ê¸‰ ê°•ì œ íŒì • ë¡œì§ (ë¬´ê²½ë ¥/ë¬´ê´€ì§ë¬´/ê¸°ìˆ ë§¤ì¹­0)
            is_forced_f = False
            f_reason = ""
            if actual_months == 0:
                is_forced_f = True
                f_reason = "ë¬´ê²½ë ¥ì(ì‹ ì…)"
            elif not is_relevant_role:
                is_forced_f = True
                f_reason = "ì§ë¬´ ë¶ˆì¼ì¹˜"
            elif k_score == 0 and v_norm < 0.3: # ê¸°ìˆ  ë§¤ì¹­ì´ ë§¤ìš° ë‚®ì€ ê²½ìš°
                is_forced_f = True
                f_reason = "ê¸°ìˆ  ì—­ëŸ‰ ë¶€ì¡±"

            if is_forced_f:
                # Fë“±ê¸‰ ì ìˆ˜ ì œí•œ (ìµœëŒ€ 59ì )
                final_raw_score = min(final_raw_score, 0.59)
            else:
                # Cë“±ê¸‰ ì´ìƒ ì ìˆ˜ ë³´ì • (ìµœì†Œ 60ì )
                if final_raw_score < 0.60:
                    final_raw_score = 0.60

            comp_data = {
                "metadata": {
                    "company_name": comp["name"],
                    "job_title": ", ".join(comp.get("target_roles", [])),
                    "industry": comp["industry"],
                    "tier": comp.get("tier", "Low")
                },
                "tech_stack": comp.get("tech_stack", []), # ë‚´ë¶€ ë¡œì§ìš©
                "raw_score": final_raw_score,
                "vector_raw": round(v_raw, 2),
                "vector_norm": round(v_norm, 2),
                "keyword_raw": round(k_score, 2),
                "meta_bonus": round(meta_bonus, 2),
                "is_forced_f": is_forced_f,
                "f_reason": f_reason
            }
            # MatchResult ëª¨ë¸ í˜¸í™˜ì„±ì„ ìœ„í•´ flat í•˜ê²Œ ì €ì¥í•˜ì§€ ì•Šê³  metadata êµ¬ì¡° ìœ ì§€í•˜ë˜,
            # ë‚´ë¶€ ë¡œì§ì—ì„œëŠ” comp_data ì ‘ê·¼
            
            # API í˜¸í™˜ì„ ìœ„í•´ company_name ë“±ì€ metadata ì•ˆì— ë„£ê³ , 
            # ì¶”ì²œ ë¡œì§ ë‚´ì—ì„œëŠ” í¸ì˜ìƒ í‚¤ ì ‘ê·¼

            tier = comp.get("tier", "Low")
            if tier not in buckets: tier = "Low"
            buckets[tier].append(comp_data)

        for t in buckets:
            buckets[t].sort(key=lambda x: x['raw_score'], reverse=True)

        return buckets

    def _convert_resume_to_text(self, resume_input: dict) -> str:
        """
        ì´ë ¥ì„œ JSON ê°ì²´ë¥¼ ì„ë² ë”© ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        """
        parts = []
        
        # 1. ìŠ¤í‚¬
        content = resume_input.get('resume_content', {})
        skills = content.get('skills', {})
        essential = skills.get('essential', [])
        additional = skills.get('additional', [])
        all_skills = essential + additional
        if all_skills:
            parts.append(f"Technical Skills: {', '.join(all_skills)}")
            
        # 2. ê²½ë ¥ (Key Tasks ìœ„ì£¼)
        experiences = content.get('professional_experience', [])
        for exp in experiences:
            role = exp.get('role', '')
            tasks = exp.get('key_tasks', [])
            parts.append(f"Role: {role}")
            if tasks:
                parts.append(f"Tasks: {', '.join(tasks)}")
                
        # 3. í”„ë¡œì íŠ¸
        projects = content.get('project_experience', [])
        for proj in projects:
            title = proj.get('project_title', '')
            achievements = proj.get('key_achievements', [])
            parts.append(f"Project: {title}")
            if achievements:
                parts.append(f"Achievements: {', '.join(achievements)}")
                
        # 4. ë¶„ì„ëœ ì§ë¬´ (Target Role)
        classification = resume_input.get('classification', {})
        role = classification.get('predicted_role', '')
        if not role:
             role = resume_input.get('target_role', '')
        if role:
            parts.append(f"Target Role: {role}")
            
        return "\n".join(parts)

    def generate_xai_feedback(self, resume_input: dict, recommendations: List[Dict]) -> str:
        """
        [ê¸°ëŠ¥ ê°•í™”] ì „ë¬¸ì ì´ê³  ê°ê´€ì ì¸ AI í”¼ë“œë°± ìƒì„±
        - ë“±ê¸‰ë³„ í†¤ ì¡°ì ˆ (S/A/B: ê¸ì •/ì „ë¬¸, C/F: ëƒ‰ì² /ë¶„ì„)
        - ì§ë¬´ ì í•©ë„ ìƒì„¸ ë¶„ì„ ë° ë³´ê°• ì œì•ˆ í¬í•¨
        """
        feedback_lines = ["\nì¢…í•© AI ì½”ì¹˜ ì˜ê²¬:"]

        if not recommendations:
            feedback_lines.append("ë¶„ì„ ê²°ê³¼, í˜„ì¬ ì´ë ¥ì„œì— ë¶€í•©í•˜ëŠ” ì¶”ì²œ ê¸°ì—…ì„ ì‹ë³„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ë ¥ì„œì˜ ê¸°ìˆ  ìŠ¤íƒ ë° ê²½ë ¥ ê¸°ìˆ ì„ ì¬ì ê²€í•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.")
            return "\n".join(feedback_lines)

        # 1. ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        top_rec = recommendations[0]
        top_company_name = top_rec['metadata']['company_name']
        top_score = top_rec['match_score']
        top_note = top_rec.get('note', '')
        
        classification = resume_input.get('classification', {})
        predicted_role = classification.get('predicted_role') or resume_input.get('target_role', 'ë¯¸ì§€ì • ì§ë¬´')
        
        content = resume_input.get('resume_content', {})
        resume_all_skills = set(content.get('skills', {}).get('essential', [])).union(set(content.get('skills', {}).get('additional', [])))
        experiences = content.get('professional_experience', [])
        projects = content.get('project_experience', [])

        # 2. [ê¸°ì—… ë§¤ì¹­ ê²°ê³¼] ì„¹ì…˜
        feedback_lines.append(f"\n[ê¸°ì—… ë§¤ì¹­ ê²°ê³¼]")
        feedback_lines.append(f"ëŒ€ìƒ ê¸°ì—…: {top_company_name}")
        feedback_lines.append(f"í‰ê°€ ë“±ê¸‰: {top_note} ({top_score}ì )")
        
        tone_summary = "ê¸ì •ì " if top_score >= 76 else "ë¶„ì„ì "
        feedback_lines.append(f"ë¶„ì„ ìš”ì•½: í•´ë‹¹ ì´ë ¥ì„œëŠ” {predicted_role} í¬ì§€ì…˜ì— ëŒ€í•´ {tone_summary}ì¸ ì •í•©ì„±ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.")

        # 3. [ì§ë¬´ ì í•©ë„ ìƒì„¸ ë¶„ì„] ì„¹ì…˜
        feedback_lines.append(f"\n[ì§ë¬´ ì í•©ë„ ìƒì„¸ ë¶„ì„]")
        
        # ê¸°ìˆ  ì—­ëŸ‰ ë¶„ì„
        tech_match_pct = int(top_rec.get('keyword_raw', 0) * 100)
        skills_list = list(resume_all_skills)
        skills_str = ', '.join(skills_list[:3]) if skills_list else "ê¸°ì´ˆ ì—­ëŸ‰"
        if tech_match_pct >= 80:
            tech_fit_msg = f"{skills_str} ì¤‘ì‹¬ì˜ í•µì‹¬ ì—­ëŸ‰ì´ ê¸°ì—… ìš”êµ¬ì‚¬í•­ê³¼ ë§¤ìš° ë†’ì€ ì¼ì¹˜ë„ë¥¼ ë³´ì…ë‹ˆë‹¤."
        elif tech_match_pct >= 50:
            tech_fit_msg = f"{skills_str} ë“± ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒì„ ë³´ìœ í•˜ê³  ìˆìœ¼ë‚˜, ì‹¤ë¬´ í™œìš© ì—­ëŸ‰ì— ëŒ€í•œ ë³´ì™„ì´ ê¶Œì¥ë©ë‹ˆë‹¤."
        else:
            tech_fit_msg = "ì§€ì› ì§ë¬´ì— í•„ìš”í•œ í•µì‹¬ ê¸°ìˆ  ìŠ¤íƒê³¼ í˜„ì¬ ë³´ìœ í•˜ì‹  ì—­ëŸ‰ ê°„ì˜ ì°¨ì´ê°€ ì‹ë³„ë˜ì—ˆìŠµë‹ˆë‹¤."
        feedback_lines.append(f"- ê¸°ìˆ  ì—­ëŸ‰: {tech_fit_msg}")

        # ì‹¤ë¬´ ê²½í—˜ ë¶„ì„
        exp_count = len(experiences)
        if exp_count >= 1:
            exp_role = experiences[0].get('role', 'ê´€ë ¨ ì§ë¬´')
            exp_fit_msg = f"{exp_role} ê²½ë ¥ì„ í†µí•œ ì‹¤ë¬´ ê¸°ì—¬ ê°€ëŠ¥ì„±ì´ ë†’ìŒìœ¼ë¡œ ë¶„ì„ë©ë‹ˆë‹¤."
        else:
            exp_fit_msg = "ì‹¤ë¬´ ê²½ë ¥ ì¦ë¹™ì´ ë¶€ì¡±í•˜ì—¬, í”„ë¡œì íŠ¸ ê²½í—˜ì„ í†µí•œ ì—­ëŸ‰ ì¦ëª…ì´ ìš”êµ¬ë©ë‹ˆë‹¤."
        feedback_lines.append(f"- ì‹¤ë¬´ ê²½í—˜: {exp_fit_msg}")

        # ì§ë¬´ ì—°ê´€ì„± ë¶„ì„
        relevance_pct = int(top_rec.get('vector_norm', 0) * 100)
        feedback_lines.append(f"- ì§ë¬´ ì—°ê´€ì„±: ì§€ì›í•˜ì‹  ì§ë¬´ì™€ ë³´ìœ í•˜ì‹  ê²½ë ¥ ê°„ì˜ ì—°ê´€ì„±ì€ {relevance_pct}% ìˆ˜ì¤€ì…ë‹ˆë‹¤.")

        # 4. [AI ë³´ê°• ì œì•ˆ] ì„¹ì…˜
        feedback_lines.append(f"\n[AI ë³´ê°• ì œì•ˆ]")
        
        proposals = []
        if top_score >= 76: # S/A/B
            proj_title = projects[0].get('project_title', 'ì£¼ìš” í”„ë¡œì íŠ¸') if projects else "ìˆ˜í–‰ í”„ë¡œì íŠ¸"
            proposals.append(f"1. í•µì‹¬ ì„±ê³¼ ìˆ˜ì¹˜í™”: {proj_title} ê²½í—˜ì˜ ì„±ê³¼ë¥¼ ì •ëŸ‰ì  ì§€í‘œ(KPI)ë¡œ ëª…ì‹œí•˜ì—¬ ê°ê´€ì„±ì„ í™•ë³´í•˜ì‹­ì‹œì˜¤.")
            proposals.append(f"2. ì§ë¬´ ì „ë¬¸ì„± ê°•ì¡°: ë©´ì ‘ ì‹œ {skills_str}ë¥¼ í™œìš©í•œ ë¬¸ì œ í•´ê²° ì‚¬ë¡€ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì–´í•„í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.")
        else: # C/F
            if not experiences:
                proposals.append("1. ì§ë¬´ ê²½ë ¥ ë³´ì™„: ì§€ì› ì§ë¬´ì™€ ì§ì ‘ì ìœ¼ë¡œ ì—°ê´€ëœ ì¸í„´ì‹­ ë˜ëŠ” ì‹¤ë¬´ í”„ë¡œì íŠ¸ ê²½í—˜ì„ í™•ë³´í•˜ì‹­ì‹œì˜¤.")
            else:
                proposals.append(f"1. ì´ë ¥ì„œ ì¬êµ¬ì„±: í˜„ì¬ì˜ {experiences[0].get('role', 'ì´ì „ ì§ë¬´')} ì¤‘ì‹¬ ê¸°ìˆ ì„ ì§€ì› ì§ë¬´ì¸ {predicted_role} ê´€ì ìœ¼ë¡œ ì¬í•´ì„í•˜ì—¬ ê¸°ìˆ í•˜ì‹­ì‹œì˜¤.")
            
            comp_stack = set(top_rec.get('tech_stack', []))
            missing = list(comp_stack - resume_all_skills)[:2]
            if missing:
                proposals.append(f"2. ê¸°ìˆ  ìŠ¤íƒ í™•ì¶©: ë¶€ì¡±í•œ {', '.join(missing)} ê´€ë ¨ ì—­ëŸ‰ì„ í•™ìŠµí•˜ê³  ì´ë¥¼ í™œìš©í•œ í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ì¶”ê°€í•˜ì‹­ì‹œì˜¤.")
            else:
                proposals.append("2. í”„ë¡œì íŠ¸ ìƒì„¸í™”: ìˆ˜í–‰í•˜ì‹  í”„ë¡œì íŠ¸ì˜ ê¸°ìˆ ì  ë‚œì´ë„ì™€ ë³¸ì¸ì˜ ê¸°ì—¬ë„ë¥¼ ë” êµ¬ì²´ì ìœ¼ë¡œ ê¸°ìˆ í•˜ì‹­ì‹œì˜¤.")

        feedback_lines.extend(proposals)

        return "\n".join(feedback_lines)

    def recommend(self, resume_input: dict):
        """
        FastAPI ë¼ìš°í„° í˜¸í™˜ìš© ë©”ì¸ ë©”ì†Œë“œ
        """
        # [ë°©ì–´ ì½”ë“œ] ê¸°ì—… ë°ì´í„° í™•ì¸
        if not self.company_data:
            return [], "ì‹œìŠ¤í…œ ì—ëŸ¬: ê¸°ì—… ë°ì´í„°(Vector DB)ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

        # 1. ì´ë ¥ì„œ í…ìŠ¤íŠ¸ ë³€í™˜
        resume_text = self._convert_resume_to_text(resume_input)
        
        # 2. ì§ë¬´ íŒŒì•…
        classification = resume_input.get('classification', {})
        role = classification.get('predicted_role', '')
        if not role:
             role = resume_input.get('target_role', 'backend') # default

        # 3. ë²¡í„° ì„ë² ë”© ë° ìœ ì‚¬ë„ ê³„ì‚°
        query_vector = self.model.encode([resume_text])
        all_vectors = self.company_data['vectors']
        vector_scores = cosine_similarity(query_vector, all_vectors)[0]

        # 4. ë²„í‚·íŒ… ë° ì ìˆ˜ ê³„ì‚°
        buckets = self._categorize_companies(self.company_data['companies'], vector_scores, resume_input, role)

        # 5. ë“±ê¸‰ ê¸°ë°˜ ê¸°ì—… ì„ ì • (Smart Regrading ë°˜ì˜)
        # resume_inputì— ì´ë¯¸ ë¶„ì„ëœ ë“±ê¸‰ì´ ìˆë‹¤ë©´ ì‚¬ìš©
        resume_evaluation = resume_input.get('evaluation') or {}
        candidate_grade = resume_evaluation.get('grade', 'B')
        
        # [Team Rule] ì—”ì§„ì´ íŒë‹¨í•œ ê°•ì œ F ì¡°ê±´ì´ ìˆëŠ”ì§€ í™•ì¸
        all_comp_data = []
        for t in buckets: all_comp_data.extend(buckets[t])
        
        is_candidate_forced_f = any(c.get('is_forced_f', False) for c in all_comp_data)
        
        if is_candidate_forced_f:
            candidate_grade = "F"
            print(f"   -> [Team Rule] Grade forced to F due to lack of experience or unrelated role.")
        elif candidate_grade == "F":
            # ë¶„ì„ APIì—ì„œëŠ” Fë¥¼ ì¤¬ìœ¼ë‚˜, ì—”ì§„ ì ìˆ˜ê°€ ë†’ê²Œ ë‚˜ì˜¨ ê²½ìš° (Ghost F êµ¬ì œ)
            # ì „ì²´ ê¸°ì—… í‰ê·  ì ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì ì¬ ë“±ê¸‰ í™•ì¸
            all_raw_scores = [c['raw_score'] for c in all_comp_data]
            if all_raw_scores:
                avg_score = sum(all_raw_scores) / len(all_raw_scores)
                if avg_score > 0.6: # Cë“±ê¸‰ ì´ìƒ ì ìˆ˜ê°€ ì¶©ë¶„íˆ ë‚˜ì˜´
                    candidate_grade = "C"
                    print(f"   -> [Ghost F Recovery] Grade F -> {candidate_grade} (Avg Score: {avg_score:.2f})")

        target_slots = self.TIER_RULES.get(candidate_grade, self.TIER_RULES["B"])
        final_selection = []
        used_companies = set()

        for required_tier in target_slots:
            selected = None
            for comp in buckets.get(required_tier, []):
                comp_name = comp['metadata']['company_name']
                if comp_name not in used_companies:
                    selected = comp
                    break

            if not selected:
                search_order = ["Top", "Mid", "Low"] if required_tier == "Top" else ["Mid", "Low", "Top"]
                for tier in search_order:
                    for comp in buckets.get(tier, []):
                        comp_name = comp['metadata']['company_name']
                        if comp_name not in used_companies:
                            selected = comp
                            break
                    if selected: break

            if selected:
                used_companies.add(selected['metadata']["company_name"])
                final_selection.append(selected)

        # 6. ì ìˆ˜ ë§¤í•‘ (Smart Calibration) ë° ê²°ê³¼ í¬ë§·íŒ…
        formatted_results = []
        for i, res in enumerate(final_selection):
            # Dynamic Scaling
            if i < len(self.SCORE_RANGES):
                min_s, max_s = self.SCORE_RANGES[i]
                final_score = self._map_score_to_range(res['raw_score'], min_s, max_s)
            else:
                final_score = round(res['raw_score'] * 100, 1)

            # Note ì„¤ì • ë° match_level ë§¤í•‘
            if i == 0:
                note = "Best Match"
                match_level = "BEST"
            elif res['raw_score'] < self.GAP_THRESHOLD:
                note = "Skill Gap"
                match_level = "GAP"
            else:
                note = "High Fit"
                match_level = "HIGH"

            # ë‚´ë¶€ ë”•ì…”ë„ˆë¦¬ ì—…ë°ì´íŠ¸ (feedback ìƒì„±ìš©)
            res['match_score'] = final_score
            res['note'] = note
            
            # API ë°˜í™˜ìš© êµ¬ì¡°ë¡œ ë³€í™˜
            # MatchResult: company_name, match_score, tier, match_type, reason
            # api/routes.py í˜¸í™˜ì„ ìœ„í•´ raw_score, is_exact_match ì¶”ê°€
            formatted_results.append({
                "metadata": res['metadata'], # ê¸°ì¡´ êµ¬ì¡° í˜¸í™˜
                "company_name": res['metadata']['company_name'], # API í•„ë“œ
                "match_score": final_score,
                "tier": res['metadata']['tier'],
                "match_type": note,
                "match_level": match_level,
                "reason": f"Tech Match: {res['keyword_raw']*100:.0f}%, Vector: {res['vector_norm']:.2f}",
                
                # [Legacy Support] api/routes.py í˜¸í™˜
                "raw_score": final_score, 
                "is_exact_match": (note == "Best Match") or (final_score >= 85),
                
                # ë‚´ë¶€ ë¡œì§ìš© í•„ë“œ ìœ ì§€ (feedback ìš©)
                "tech_stack": res['tech_stack'],
                "note": note,
                "keyword_raw": res['keyword_raw'],
                "vector_norm": res['vector_norm']
            })

        # 7. í”¼ë“œë°± ìƒì„±
        report = self.generate_xai_feedback(resume_input, formatted_results)

        return formatted_results, report

# Singleton Instance
resume_engine = MatchingEngine()
