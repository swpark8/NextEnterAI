import json
import numpy as np
import os
import pickle
import re
from pathlib import Path
from typing import List, Dict, Tuple, Any, Optional
from dotenv import load_dotenv

# [í•µì‹¬] .env íŒŒì¼ ë¡œë“œë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    from dotenv import load_dotenv
except ImportError:
    print("âš ï¸ 'python-dotenv' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. 'pip install python-dotenv'ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    # ë”ë¯¸ í•¨ìˆ˜ ì •ì˜ (ì—ëŸ¬ ë°©ì§€)
    def load_dotenv(dotenv_path=None): pass

# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì²´í¬
try:
    from sentence_transformers import SentenceTransformer
    from sklearn.metrics.pairwise import cosine_similarity
    from openai import OpenAI
except ImportError:
    print("âš ï¸ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. requirements.txtë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    
# ==========================================
# 0. í™˜ê²½ ë³€ìˆ˜(.env) ë¡œë“œ ë° ì§„ë‹¨
# ==========================================
print("\n[System] Loading environment variables...")
env_path = Path.cwd() / ".env" # í˜„ì¬ ìœ„ì¹˜ì—ì„œ .env ì°¾ê¸°

if env_path.exists():
    load_dotenv(dotenv_path=env_path)
    print(f"âœ… Found .env file at: {env_path}")
else:
    load_dotenv() # ê¸°ë³¸ ê²½ë¡œ íƒìƒ‰
    print("â„¹ï¸ No explicit .env file found in root. Searching default locations...")



# ==========================================
# 1. ìœ í‹¸ë¦¬í‹° ë° ê²½ë¡œ ì„¤ì • (Infrastructure)
# ==========================================
def get_data_path() -> Path:
    cwd = Path.cwd()
    # ë‹¤ì–‘í•œ ê²½ë¡œ ì‹œë„
    candidates = [
        cwd / "app" / "data",
        Path(__file__).parent / "app" / "data",
        Path(__file__).parent.parent / "app" / "data", # ìƒìœ„ í´ë” ê³ ë ¤
        cwd / "services" / "data", # services í´ë” êµ¬ì¡° ëŒ€ì‘
        cwd / "data"
    ]
    
    for path in candidates:
        if path.exists():
            return path
            
    # ëª» ì°¾ìœ¼ë©´ ìƒì„± ì‹œë„ (ì—ëŸ¬ ë°©ì§€)
    try:
        (cwd / "data").mkdir(exist_ok=True)
        return cwd / "data"
    except (FileNotFoundError, PermissionError) as e:
        print(f"âš ï¸ Failed to create data directory: {e}")
        return cwd / "app" / "data"

class DataLoader:
    def __init__(self):
        self.base_path = get_data_path()
        self.file_names = {
            "resumes": "final_resume_600.json",
            "companies": "company_50_pool.json",
            "metadata": "final_metadata_600.json",
            "seeds": "final_jd_seeds_fixed.json" 
        }

# ==========================================
# 2. ë§¤ì¹­ ì—”ì§„ í´ë˜ìŠ¤ (Core Logic)
# ==========================================
class MatchingEngine:
    # --------------------------------------
    # ìƒìˆ˜ ë° ì„¤ì • (Configuration)
    # --------------------------------------
    WEIGHT_VECTOR = 0.55       # S-BERT ìœ ì‚¬ë„ ê°€ì¤‘ì¹˜
    WEIGHT_KEYWORD = 0.35      # ìŠ¤í‚¬ ë§¤ì¹­ ê°€ì¤‘ì¹˜
    BONUS_ROLE_MATCH = 0.10    # ì§ë¬´ ì¼ì¹˜ ë³´ë„ˆìŠ¤ (Max)
    GAP_THRESHOLD = 50.0       # ê¸°ìˆ  ê°­(Skill Gap) íŒë‹¨ ê¸°ì¤€ ì ìˆ˜

    # ë“±ê¸‰ë³„ ì ìˆ˜ êµ¬ê°„ (ì—„ê²© ì ìš©)
    SCORE_RANGES = [
        (88.0, 97.0), # S (Rank 1)
        (77.0, 86.0), # A (Rank 2)
        (66.0, 75.0)  # B (Rank 3)
    ]

    # í‹°ì–´ë³„ ì¶”ì²œ ì¿¼í„° (ì°¸ê³ ìš©)
    TIER_RULES = {
        "S": ["Top", "Top", "Mid"],
        "A": ["Top", "Mid", "Mid"],
        "B": ["Mid", "Mid", "Low"],
        "C": ["Mid", "Low", "Low"],
        "F": ["Low", "Low", "Low"]
    }
    # [NEW] í˜„ì‹¤ì ì¸ Raw Score ê¸°ì¤€ì  (ì •ê·œí™” í›„ ê¸°ì¤€)
    RAW_SCORE_MIN = 0.30
    RAW_SCORE_MAX = 0.95
    GAP_THRESHOLD_RATIO = 0.50  # 0.5ì (50ì ) ë¯¸ë§Œì´ë©´ ê²½ê³ 


    def __init__(self):
        print("âš™ï¸ Initializing Matching Engine (Dual List Applied)...")
        self.loader = DataLoader()
        self.base_path = self.loader.base_path
        
        # 1. OpenAI ì´ˆê¸°í™”
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.openai_client = None
        if self.openai_api_key:
            try:
                self.openai_client = OpenAI(api_key=self.openai_api_key)
                print("âœ… OpenAI Client Connected")
            except Exception as e:
                print(f"âš ï¸ OpenAI Connection Failed: {e}")
        else:
            print("âš ï¸ No OPENAI_API_KEY found")

        # 2.0 Gemini ì´ˆê¸°í™” (Backup)
        self.google_api_key = os.getenv("GOOGLE_API_KEY")
        self.gemini_client = None
        if self.google_api_key:
            try:
                from google import genai
                self.gemini_client = genai.Client(api_key=self.google_api_key)
                print("âœ… Google Gemini Client Connected (Backup - gemini-2.0-flash)")
            except Exception as e:
                print(f"âš ï¸ Google Gemini Connection Failed: {e}")
        
        # 2. ëª¨ë¸ ë¡œë“œ
        try:
            # User Modified Model
            self.model = SentenceTransformer('jhgan/ko-sroberta-multitask')
            print("[Start] Matching Engine initializing...")
        except Exception as e:
            print(f"âš ï¸ Model Load Failed: {e}")
            self.model = None

        # 3. ë°ì´í„° ë¡œë“œ (ìºì‹± ì ìš©)
        loaded_data = self._load_company_vectors()
        if loaded_data:
            self.companies = loaded_data['companies']
            self.company_vectors = loaded_data['vectors']
            print(f"âœ… Engine Ready: {len(self.companies)} companies loaded.")
        else:
            self.companies = []
            self.company_vectors = None

    # --------------------------------------
    # ë‚´ë¶€ í•¨ìˆ˜: ë°ì´í„° ë¡œë”© ë° ë²¡í„°í™”
    # --------------------------------------
    def _load_company_vectors(self):
        """PKL ìºì‹œ ìš°ì„  ë¡œë“œ, ì—†ìœ¼ë©´ JSON ë¹Œë“œ"""
        pkl_path = self.base_path / "company_jd_vectors.pkl"
        json_path = self.base_path / "company_50_pool.json"
        
        if pkl_path.exists():
            try:
                with open(pkl_path, 'rb') as f:
                    data = pickle.load(f)
                if isinstance(data, dict) and 'vectors' in data:
                    return data
            except (FileNotFoundError, PermissionError, Exception) as e:
                print(f"âš ï¸ Failed to load pickle cache: {e}")

        if json_path.exists():
            try:
                with open(json_path, 'r', encoding='utf-8') as f:
                    companies = json.load(f)
                
                if not self.model: return {'companies': companies, 'vectors': None}

                texts = []
                for comp in companies:
                    # ê¸°ì—… ì •ë³´ í…ìŠ¤íŠ¸í™” (ì¤‘ìš”: ëª¨ë“  í•„ë“œ í¬í•¨)
                    parts = [
                        comp.get('name', ''),
                        comp.get('industry', ''),
                        " ".join(comp.get('tech_stack', [])),
                        " ".join(comp.get('target_roles', [])),
                        comp.get('location', '')
                    ]
                    texts.append(" ".join(parts))
                
                vectors = self.model.encode(texts, show_progress_bar=False, batch_size=32)
                
                # ìºì‹œ ì €ì¥
                try:
                    with open(pkl_path, 'wb') as f:
                        pickle.dump({'companies': companies, 'vectors': vectors}, f)
                except (FileNotFoundError, PermissionError) as e:
                    print(f"âš ï¸ Failed to save pickle cache: {e}")
                
                return {'companies': companies, 'vectors': vectors}
            except (FileNotFoundError, PermissionError, json.JSONDecodeError) as e:
                print(f"âš ï¸ Failed to load company data: {e}")
                return None
        return None

    # --------------------------------------
    # ë‚´ë¶€ í•¨ìˆ˜: í…ìŠ¤íŠ¸ ë° ì ìˆ˜ ì²˜ë¦¬ (Utils)
    # --------------------------------------
    def _normalize_text(self, text: str) -> str:
        """ëŒ€ì†Œë¬¸ì í†µì¼ ë° íŠ¹ìˆ˜ë¬¸ì ì œê±°"""
        if not text: return ""
        text = text.lower()
        text = re.sub(r'[^a-z0-9ê°€-í£\s]', '', text)
        return text.strip()

    def _normalize_vector_score(self, val: float) -> float:
        """S-BERT ì ìˆ˜ ì •ê·œí™” (0.15~0.75 -> 0.0~1.0)"""
        min_bound = 0.15
        max_bound = 0.75
        normalized = (val - min_bound) / (max_bound - min_bound)
        return max(0.0, min(1.0, normalized))

    def get_grade(self, score: float) -> str:
        """ì ìˆ˜ ê¸°ë°˜ ë“±ê¸‰ íŒì •"""
        if score >= 88: return "S"
        if score >= 78: return "A"
        if score >= 68: return "B"
        if score >= 58: return "C"
        return "F"
    
    def _map_score_to_range(self, raw_score: float, target_min: float, target_max: float) -> float:
        """
        [Dynamic Scaling] í˜„ì‹¤ì ì¸ ì…ë ¥ ë²”ìœ„(Raw Score)ë¥¼ ëª©í‘œ ë²”ìœ„ë¡œ ë§¤í•‘
        """
        input_min, input_max = self.RAW_SCORE_MIN, self.RAW_SCORE_MAX

        normalized = (raw_score - input_min) / (input_max - input_min)
        normalized = max(0.0, min(1.0, normalized))

        scaled_score = target_min + (normalized * (target_max - target_min))
        return round(scaled_score, 1)

    def _convert_resume_to_text(self, resume_input: Dict) -> str:
        """ì´ë ¥ì„œ ê°ì²´ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        content = resume_input.get('resume_content', {})
        text_parts = []

        # 1. raw_text (ì›ë³¸ í…ìŠ¤íŠ¸)ê°€ ìˆìœ¼ë©´ ìµœìš°ì„ ì ìœ¼ë¡œ í¬í•¨
        if isinstance(content, dict) and content.get('raw_text'):
            text_parts.append(content['raw_text'])

        # 2. target_role (í¬ë§ ì§ë¬´) ì¶”ê°€
        target_role = resume_input.get('target_role', '')
        if target_role:
            text_parts.append(target_role)
        
        if isinstance(content, dict):
            # 3. skills (ê¸°ìˆ  ìŠ¤íƒ) ì¶”ì¶œ
            skills = content.get('skills', {})
            user_skills = []
            if isinstance(skills, dict):
                user_skills = skills.get('essential', []) + skills.get('additional', [])
            elif isinstance(skills, list):
                user_skills = skills
            if user_skills:
                text_parts.append(" ".join(user_skills))
            
            # 4. professional_experience (ê²½ë ¥ ì‚¬í•­) ì¶”ì¶œ - ì—­í•  ë° ì£¼ìš” ì—…ë¬´ í¬í•¨
            exp_texts = []
            for exp in content.get('professional_experience', []):
                if exp.get('role'): exp_texts.append(exp['role'])
                tasks = exp.get('key_tasks', [])
                if isinstance(tasks, list):
                    exp_texts.extend(tasks)
            if exp_texts:
                text_parts.append(" ".join(exp_texts))

            # 5. education (í•™ë ¥ ì‚¬í•­) ì¶”ì¶œ - ì „ê³µ ë° í•™ìœ„ ë°˜ì˜
            edu_texts = []
            for edu in content.get('education', []):
                if edu.get('major'): edu_texts.append(edu['major'])
                if edu.get('degree'): edu_texts.append(edu['degree'])
            if edu_texts:
                text_parts.append(" ".join(edu_texts))
        else:
            text_parts.append(str(content))
            
        # ëª¨ë“  íŒŒíŠ¸ë¥¼ ê³µë°±ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ ë³‘í•©
        return " ".join([p for p in text_parts if p]).strip()

    # --------------------------------------
    # ë‚´ë¶€ í•¨ìˆ˜: í•µì‹¬ ë¡œì§ (Logic)
    # --------------------------------------
    def _calculate_keyword_score(self, resume_text: str, tech_stack: List[str]) -> float:
        """ê¸°ìˆ  ìŠ¤íƒ ì»¤ë²„ë¦¬ì§€ ê³„ì‚°"""
        if not tech_stack: return 0.5
        resume_lower = resume_text.lower()
        match_count = sum(1 for skill in tech_stack if skill.lower() in resume_lower)
        return match_count / len(tech_stack)

    def _calculate_metadata_bonus(self, candidate_role: str, company_target_roles: List[str]) -> float:
        """ì§ë¬´ ì—°ê´€ì„± ë³´ë„ˆìŠ¤ (Fullstack, AI, UI/UX íŠ¹í™”)"""
        if not candidate_role or not company_target_roles: return 0.0
        cand_role_lower = candidate_role.lower()
        
        for role in company_target_roles:
            role_lower = role.lower()
            if role_lower in cand_role_lower or cand_role_lower in role_lower:
                return self.BONUS_ROLE_MATCH
            if "fullstack" in cand_role_lower and (role_lower in ["backend", "frontend"]):
                return self.BONUS_ROLE_MATCH * 0.8
            if "ai" in cand_role_lower or "llm" in cand_role_lower:
                if any(kw in role_lower for kw in ["nlp", "llm", "vision", "ai", "ml", "data"]):
                    return self.BONUS_ROLE_MATCH
            if "ui/ux" in cand_role_lower or "designer" in cand_role_lower:
                if any(kw in role_lower for kw in ["design", "ui", "ux", "product", "creative"]):
                    return self.BONUS_ROLE_MATCH
        return 0.0

    def _check_role_relevance(self, target_category: str, current_role: str) -> bool:
        """ì§ë¬´ ì—°ê´€ì„± ì²´í¬ (í‚¤ì›Œë“œ ë§¤ì¹­)"""
        if not target_category or not current_role: return False
        target_category = target_category.lower()
        current_role = current_role.lower()
        
        relevance_keywords = [target_category, 'ê¸°íš', 'ê°œë°œ', 'developer', 'manager', 'engineer', 'design']
        
        if "designer" in target_category or "ui/ux" in target_category:
            relevance_keywords.extend(['art', 'creative', 'ux', 'ui', 'ë””ìì¸', 'ë””ìì´ë„ˆ', 'í¼ë¸”ë¦¬ì…”'])
        if "ai" in target_category or "llm" in target_category:
            relevance_keywords.extend(['researcher', 'scientist', 'nlp', 'ml', 'data', 'lab', 'ì—°êµ¬ì›'])
        
        return any(kw in current_role for kw in relevance_keywords)

    def _calculate_missing_skills(self, resume_input: Dict, company_stack: List[str]) -> List[str]:
        """ë¶€ì¡±í•œ ìŠ¤í‚¬ ë„ì¶œ"""
        if not company_stack: return []
        content = resume_input.get('resume_content', {})
        user_skills = []
        if isinstance(content, dict):
            skills = content.get('skills', {})
            if isinstance(skills, dict):
                user_skills = skills.get('essential', []) + skills.get('additional', [])
        
        user_norm = [s.lower().strip() for s in user_skills]
        missing = []
        for req in company_stack:
            req_l = req.lower().strip()
            if req_l in user_norm: continue
            if not any(req_l in u or u in req_l for u in user_norm):
                missing.append(req)
        return missing

    def _calculate_ats_detail(self, missing_skills: List[str], company_stack: List[str]) -> Dict[str, Any]:
        """ATS ì ìˆ˜ ìƒì„¸ ê³„ì‚°"""
        total = len(company_stack)
        if total == 0: return {"score": 100, "matched": 0, "total": 0}
        matched = total - len(missing_skills)
        return {"score": int((matched/total)*100), "matched": matched, "total": total}

    def verify_and_regrade(self, resume_input: dict, final_raw_score: float) -> float:
        """
        [Ghost F í•´ê²°] í…ìŠ¤íŠ¸ ë§¤ì¹­ì€ ì¤€ìˆ˜í•˜ë‚˜ ì ìˆ˜ê°€ ë‚®ê²Œ ë‚˜ì˜¨ ê²½ìš° ë³´ì •
        ê²½ë ¥(40%), í”„ë¡œì íŠ¸(30%), ê¸°ìˆ (20%), í•™ë ¥(10%) ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì •ë°€ ì¬ì±„ì 
        """
        content = resume_input.get('resume_content', {})
        
        # 1. í•™ë ¥ ì ìˆ˜ (10%)
        edu_score = 0.0
        for edu in content.get('education', []):
            major = edu.get('major', '').lower()
            if any(kw in major for kw in ['ì»´í“¨í„°', 'computer', 'ì†Œí”„íŠ¸ì›¨ì–´', 'software', 'IT', 'ì „ì‚°']):
                edu_score = 0.1
                break
        
        # 2. ê²½ë ¥ ì ìˆ˜ (40%)
        exp_score = 0.0
        experiences = content.get('professional_experience', [])
        if experiences:
            exp_score = 0.2 # ê¸°ë³¸ ê²½ë ¥ ë³´ìœ 
            for exp in experiences:
                period = str(exp.get('period', ''))
                # 3ë…„ ì´ìƒ ê²½ë ¥ ì‹œ ê°€ì¤‘ì¹˜ ìµœëŒ€
                if any(kw in period for kw in ['36ê°œì›”', '3ë…„', '48ê°œì›”', '4ë…„', '5ë…„', '60ê°œì›”']):
                    exp_score = 0.4
                    break
        
        # 3. í”„ë¡œì íŠ¸ ì ìˆ˜ (30%)
        proj_score = 0.0
        if content.get('project_experience', []):
            proj_score = 0.3

        # 4. ê¸°ìˆ  ì ìˆ˜ (ê¸°ì¡´ final_raw_score í™œìš© - 20%)
        tech_score = final_raw_score * 0.2

        # ìµœì¢… ë³´ì • ì ìˆ˜
        refined_score = tech_score + exp_score + proj_score + edu_score
        
        # [Ghost F ë°©ì–´] í•™ë ¥ê³¼ ê²½ë ¥ì´ ì–‘í˜¸í•˜ë©´ ìµœì†Œ Cë“±ê¸‰(0.6) í•˜í•œì„  ë³´ì¥
        if (edu_score >= 0.1 or exp_score >= 0.3) and refined_score < 0.6:
            refined_score = 0.6
            
        return min(1.0, refined_score)

    # --------------------------------------
    # ê¸°ì—… ë¶„ë¥˜ ë° ì ìˆ˜ ì‚°ì • ë¡œì§ (Main Logic)
    # --------------------------------------
    def _categorize_companies(self, all_companies, vector_scores, resume_input, candidate_role):
        buckets = {"Top": [], "Mid": [], "Low": []}
        resume_text = self._convert_resume_to_text(resume_input)
        
        # 0. ì´ë ¥ì„œ ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        content = resume_input.get('resume_content', {})
        experiences = content.get('professional_experience', [])
        
        actual_months = 0
        current_exp_role = ""
        if experiences:
            period_str = str(experiences[0].get('period', '0'))
            current_exp_role = experiences[0].get('role', '')
            nums = re.findall(r'\d+', period_str)
            actual_months = int(nums[0]) if nums else 0
            
        is_relevant_role = self._check_role_relevance(candidate_role, current_exp_role)

        for idx, comp in enumerate(all_companies):
            # 1. ë²¡í„° ì ìˆ˜ ì •ê·œí™”
            v_raw = float(vector_scores[idx])
            v_norm = self._normalize_vector_score(v_raw)

            # 2. í‚¤ì›Œë“œ ì ìˆ˜
            k_score = self._calculate_keyword_score(resume_text, comp.get('tech_stack', []))

            # Semantic Rescue (í‚¤ì›Œë“œ 0ì  êµ¬ì œ)
            if k_score == 0.0 and v_norm > 0.5: k_score = 0.2

            # 3. ê°€ì¤‘ì¹˜ ì ìš© í•©ì‚°
            hybrid_score = (v_norm * self.WEIGHT_VECTOR) + (k_score * self.WEIGHT_KEYWORD)

            # 4. ë©”íƒ€ë°ì´í„° ë³´ë„ˆìŠ¤
            meta_bonus = self._calculate_metadata_bonus(candidate_role, comp.get('target_roles', []))

            base_hybrid_score = hybrid_score + meta_bonus
            
            # [ì¶”ê°€] ì§ë¬´ ë¶ˆì¼ì¹˜ ê°ì  (Conflict Penalty)
            if meta_bonus == 0 and v_norm > 0.4:
                base_hybrid_score -= 0.15 
            
            # 5. [Ghost F í•´ê²°] ì •ë°€ ì¬ì±„ì 
            final_raw_score = self.verify_and_regrade(resume_input, base_hybrid_score)

            # 6. [Team Rule] Fë“±ê¸‰ ê°•ì œ íŒì • ì¡°ê±´ ê°•í™”
            is_forced_f = False
            f_reason = ""
            
            # (1) ë¬´ê²½ë ¥
            if actual_months == 0:
                is_forced_f = True
                f_reason = "ì‹¤ë¬´ ê²½ë ¥ ì—†ìŒ(ì‹ ì…)"
            # (2) ì§ë¬´ ë¶ˆì¼ì¹˜
            elif not is_relevant_role:
                is_forced_f = True
                f_reason = "ì§ë¬´ ì—°ê´€ì„± ë¶€ì¡±"
            # (3) ê¸°ìˆ  ì—­ëŸ‰ ë¯¸ë‹¬
            elif k_score == 0 and v_norm < 0.3:
                is_forced_f = True
                f_reason = "í•µì‹¬ ê¸°ìˆ  ì—­ëŸ‰ ë¶€ì¡±"
            # (4) ì´ë ¥ì„œ ë‚´ìš© ë¶€ì¡± (New)
            elif len(resume_text) < 50:
                is_forced_f = True
                f_reason = "ì´ë ¥ì„œ ë‚´ìš© ë¶€ì¡±"

            if is_forced_f:
                # Fë“±ê¸‰ ì ìˆ˜ ì œí•œ (ìµœëŒ€ 59ì )
                final_raw_score = min(final_raw_score, 0.59)
            else:
                # Cë“±ê¸‰ ì´ìƒ ì ìˆ˜ ë³´ì • (ìµœì†Œ 60ì )
                if final_raw_score < 0.60:
                    final_raw_score = 0.60
            
            # 100ì  ë§Œì  í™˜ì‚°
            final_score_100 = final_raw_score * 100

            # 7. ë¶€ì¡±í•œ ìŠ¤í‚¬ ê³„ì‚°
            missing_skills = self._calculate_missing_skills(resume_input, comp.get('tech_stack', []))
            
            comp_data = {
                "metadata": {
                    "company_name": comp["name"],
                    "job_title": ", ".join(comp.get("target_roles", [])),
                    "industry": comp["industry"],
                    "tier": comp.get("tier", "Low")
                },
                "tech_stack": comp.get("tech_stack", []),
                "raw_score": final_score_100,
                "vector_raw": round(v_raw, 2),
                "vector_norm": round(v_norm, 2),
                "keyword_raw": round(k_score, 2),
                "meta_bonus": round(meta_bonus, 2),
                "is_forced_f": is_forced_f,
                "f_reason": f_reason,
                "missing_skills": missing_skills
            }

            tier = comp.get("tier", "Low")
            if tier not in buckets: tier = "Low"
            buckets[tier].append(comp_data)

        for t in buckets:
            buckets[t].sort(key=lambda x: x['raw_score'], reverse=True)

        return buckets

    # --------------------------------------
    # [New] AI í”¼ë“œë°± ìƒì„± (Advanced Feedback)
    # --------------------------------------
    def _generate_rule_based_feedback(self, resume_input: dict, recommendations: List[Dict]) -> str:
        """
        ì „ë¬¸ì ì´ê³  ê°ê´€ì ì¸ AI í”¼ë“œë°± ìƒì„±
        - ë“±ê¸‰ë³„ í†¤ ì¡°ì ˆ ë° ìƒì„¸ ë¶„ì„
        - [ìˆ˜ì •] ê¸°ì—… ë§¤ì¹­ ê²°ê³¼ë¥¼ ë§¨ ë’¤ë¡œ ì´ë™
        - [ìˆ˜ì •] ì§ë¬´ ì—°ê´€ì„±ì„ ìˆ˜ì¹˜ ëŒ€ì‹  ì •ì„±ì  í‘œí˜„(ìµœì í•©/ì ë‹¹í•˜ë‹¤/ë¶€ì¡±í•˜ë‹¤)ìœ¼ë¡œ ë³€ê²½
        """
        feedback_lines = ["\nì¢…í•© AI ì½”ì¹˜ ì˜ê²¬:"]

        if not recommendations:
            feedback_lines.append("ë¶„ì„ ê²°ê³¼, í˜„ì¬ ì´ë ¥ì„œì— ë¶€í•©í•˜ëŠ” ì¶”ì²œ ê¸°ì—…ì„ ì‹ë³„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ë ¥ì„œì˜ ê¸°ìˆ  ìŠ¤íƒ ë° ê²½ë ¥ ê¸°ìˆ ì„ ì¬ì ê²€í•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.")
            return "\n".join(feedback_lines)

        # 1. ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        top_rec = recommendations[0]
        # ì¶”ì²œ ë¦¬ìŠ¤íŠ¸ êµ¬ì¡° í˜¸í™˜ì„± (metadata ì•ˆì— ìˆê±°ë‚˜ top levelì— ìˆê±°ë‚˜)
        top_company_name = top_rec.get('metadata', {}).get('company_name') or top_rec.get('company_name', 'ì¶”ì²œ ê¸°ì—…')
        top_score = top_rec['match_score']
        # noteëŠ” match_typeìœ¼ë¡œ ë§¤í•‘
        top_note = top_rec.get('match_type', 'Good Fit')
        
        classification = resume_input.get('classification', {})
        predicted_role = classification.get('predicted_role') or resume_input.get('target_role', 'ë¯¸ì§€ì • ì§ë¬´')
        
        content = resume_input.get('resume_content', {})
        skills_data = content.get('skills', {})
        resume_all_skills = set()
        if isinstance(skills_data, dict):
             resume_all_skills = set(skills_data.get('essential', [])).union(set(skills_data.get('additional', [])))

        experiences = content.get('professional_experience', [])
        projects = content.get('project_experience', [])

        # ========================================================
        # [ìˆœì„œ ë³€ê²½] ìƒì„¸ ë¶„ì„ ë‚´ìš©ì„ ë¨¼ì € êµ¬ì„±í•˜ê³ , ë§¤ì¹­ ê²°ê³¼ëŠ” ë§¨ ë’¤ë¡œ ë³´ëƒ…ë‹ˆë‹¤.
        # ========================================================

        # 2. [ì§ë¬´ ì í•©ë„ ìƒì„¸ ë¶„ì„] ì„¹ì…˜
        job_fit_lines = ["\n[ì§ë¬´ ì í•©ë„ ìƒì„¸ ë¶„ì„]"]
        
        # ê¸°ìˆ  ì—­ëŸ‰ ë¶„ì„
        tech_match_pct = int(top_rec.get('keyword_raw', 0) * 100)
        skills_list = list(resume_all_skills)
        skills_str = ', '.join(skills_list[:3]) if skills_list else "ê¸°ì´ˆ ì—­ëŸ‰"
        if tech_match_pct >= 80:
            tech_fit_msg = f"{skills_str} ì¤‘ì‹¬ì˜ í•µì‹¬ ì—­ëŸ‰ì´ ê¸°ì—… ìš”êµ¬ì‚¬í•­ê³¼ ë§¤ìš° ë†’ì€ ì¼ì¹˜ë„ë¥¼ ë³´ì…ë‹ˆë‹¤."
        elif tech_match_pct >= 50:
            tech_fit_msg = f"{skills_str} ë“± ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒì„ ë³´ìœ í•˜ê³  ìˆìœ¼ë‚˜, ì‹¤ë¬´ í™œìš© ì—­ëŸ‰ì— ëŒ€í•œ ë³´ì™„ì´ ê¶Œì¥ë©ë‹ˆë‹¤."
        else:
            tech_fit_msg = "ì§€ì› ì§ë¬´ì— í•„ìš”í•œ í•µì‹¬ ê¸°ìˆ  ìŠ¤íƒê³¼ í˜„ì¬ ë³´ìœ í•˜ì‹  ì—­ëŸ‰ ê°„ì˜ ì°¨ì´ê°€ ì‹ë³„ë˜ì—ˆìŠµë‹ˆë‹¤."
        job_fit_lines.append(f"- ê¸°ìˆ  ì—­ëŸ‰: {tech_fit_msg}")

        # ì‹¤ë¬´ ê²½í—˜ ë¶„ì„
        exp_count = len(experiences)
        if exp_count >= 1:
            exp_role = experiences[0].get('role', 'ê´€ë ¨ ì§ë¬´')
            exp_fit_msg = f"{exp_role} ê²½ë ¥ì„ í†µí•œ ì‹¤ë¬´ ê¸°ì—¬ ê°€ëŠ¥ì„±ì´ ë†’ìŒìœ¼ë¡œ ë¶„ì„ë©ë‹ˆë‹¤."
        else:
            exp_fit_msg = "ì‹¤ë¬´ ê²½ë ¥ ì¦ë¹™ì´ ë¶€ì¡±í•˜ì—¬, í”„ë¡œì íŠ¸ ê²½í—˜ì„ í†µí•œ ì—­ëŸ‰ ì¦ëª…ì´ ìš”êµ¬ë©ë‹ˆë‹¤."
        job_fit_lines.append(f"- ì‹¤ë¬´ ê²½í—˜: {exp_fit_msg}")

        # [ìˆ˜ì •] ì§ë¬´ ì—°ê´€ì„± ë¶„ì„ - í¼ì„¼íŠ¸ ëŒ€ì‹  ì •ì„±ì  í‘œí˜„ ì‚¬ìš©
        relevance_pct = int(top_rec.get('vector_norm', 0) * 100)
        if relevance_pct >= 80:
            relevance_term = "ìµœì í•© ìˆ˜ì¤€"
        elif relevance_pct >= 60:
            relevance_term = "ì ë‹¹í•œ ìˆ˜ì¤€"
        else:
            relevance_term = "ë‹¤ì†Œ ë¶€ì¡±í•œ ìˆ˜ì¤€"
        
        job_fit_lines.append(f"- ì§ë¬´ ì—°ê´€ì„±: ì§€ì›í•˜ì‹  ì§ë¬´ì™€ ë³´ìœ í•˜ì‹  ê²½ë ¥ ê°„ì˜ ì—°ê´€ì„±ì€ {relevance_term}ìœ¼ë¡œ ë¶„ì„ë©ë‹ˆë‹¤.")

        # 3. [AI ë³´ê°• ì œì•ˆ] ì„¹ì…˜
        proposal_lines = ["\n[AI ë³´ê°• ì œì•ˆ]"]
        
        proposals = []
        if top_score >= 76: # S/A/B
            proj_title = projects[0].get('project_title', 'ì£¼ìš” í”„ë¡œì íŠ¸') if projects else "ìˆ˜í–‰ í”„ë¡œì íŠ¸"
            proposals.append(f"1. í•µì‹¬ ì„±ê³¼ ìˆ˜ì¹˜í™”: {proj_title} ê²½í—˜ì˜ ì„±ê³¼ë¥¼ ì •ëŸ‰ì  ì§€í‘œ(KPI)ë¡œ ëª…ì‹œí•˜ì—¬ ê°ê´€ì„±ì„ í™•ë³´í•˜ì‹­ì‹œì˜¤.")
            proposals.append(f"2. ì§ë¬´ ì „ë¬¸ì„± ê°•ì¡°: ë©´ì ‘ ì‹œ {skills_str}ë¥¼ í™œìš©í•œ ë¬¸ì œ í•´ê²° ì‚¬ë¡€ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì–´í•„í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.")
        else: # C/F
            if not experiences:
                proposals.append("1. ì§ë¬´ ê²½ë ¥ ë³´ì™„: ì§€ì› ì§ë¬´ì™€ ì§ì ‘ì ìœ¼ë¡œ ì—°ê´€ëœ ì¸í„´ì‹­ ë˜ëŠ” ì‹¤ë¬´ í”„ë¡œì íŠ¸ ê²½í—˜ì„ í™•ë³´í•˜ì‹­ì‹œì˜¤.")
            else:
                proposals.append(f"1. ì´ë ¥ì„œ ì¬êµ¬ì„±: í˜„ì¬ì˜ {experiences[0].get('role', 'ì´ì „ ì§ë¬´')} ì¤‘ì‹¬ ê¸°ìˆ ì„ ì§€ì› ì§ë¬´ì¸ {predicted_role} ê´€ì ìœ¼ë¡œ ì¬í•´ì„í•˜ì—¬ ê¸°ìˆ í•˜ì‹­ì‹œì˜¤.")
            
            comp_stack = set(top_rec.get('tech_stack', []))
            missing = list(comp_stack - resume_all_skills)[:2]
            if missing:
                proposals.append(f"2. ê¸°ìˆ  ìŠ¤íƒ í™•ì¶©: ë¶€ì¡±í•œ {', '.join(missing)} ê´€ë ¨ ì—­ëŸ‰ì„ í•™ìŠµí•˜ê³  ì´ë¥¼ í™œìš©í•œ í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ì¶”ê°€í•˜ì‹­ì‹œì˜¤.")
            else:
                proposals.append("2. í”„ë¡œì íŠ¸ ìƒì„¸í™”: ìˆ˜í–‰í•˜ì‹  í”„ë¡œì íŠ¸ì˜ ê¸°ìˆ ì  ë‚œì´ë„ì™€ ë³¸ì¸ì˜ ê¸°ì—¬ë„ë¥¼ ë” êµ¬ì²´ì ìœ¼ë¡œ ê¸°ìˆ í•˜ì‹­ì‹œì˜¤.")

        proposal_lines.extend(proposals)

        # 4. [ê¸°ì—… ë§¤ì¹­ ê²°ê³¼] ì„¹ì…˜ (ë§¨ ë’¤ë¡œ ì´ë™)
        match_result_lines = ["\n[ê¸°ì—… ë§¤ì¹­ ê²°ê³¼]"]
        match_result_lines.append(f"ëŒ€ìƒ ê¸°ì—…: {top_company_name}")
        match_result_lines.append(f"í‰ê°€ ë“±ê¸‰: {top_note} ({top_score}ì )")
        
        tone_summary = "ê¸ì •ì " if top_score >= 76 else "ë¶„ì„ì "
        match_result_lines.append(f"ë¶„ì„ ìš”ì•½: í•´ë‹¹ ì´ë ¥ì„œëŠ” {predicted_role} í¬ì§€ì…˜ì— ëŒ€í•´ {tone_summary}ì¸ ì •í•©ì„±ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.")

        # ìµœì¢… ì¡°í•© (ìˆœì„œ: ì§ë¬´ ì í•©ë„ -> ë³´ê°• ì œì•ˆ -> ê¸°ì—… ë§¤ì¹­ ê²°ê³¼)
        feedback_lines.extend(job_fit_lines)
        feedback_lines.extend(proposal_lines)
        feedback_lines.extend(match_result_lines)

        return "\n".join(feedback_lines)

    # ==========================================
    # ë©”ì¸ ë©”ì†Œë“œ (FastAPI í˜¸í™˜)
    # ==========================================
    def _ask_llm(self, prompt: str) -> str:
        """OpenAIì™€ Geminië¥¼ ëª¨ë‘ ì‹œë„í•˜ëŠ” Fallback LLM í˜¸ì¶œê¸°"""
        
        # 1. Try OpenAI
        if self.openai_client:
            try:
                response = self.openai_client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ ì»¤ë¦¬ì–´ ì½”ì¹˜ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=500
                )
                return response.choices[0].message.content.strip()
            except Exception as e:
                print(f"âš ï¸ OpenAI request failed: {e}")
        
        # 2. Try Gemini (Fallback)
        # 2. Try Gemini (Fallback)
        if self.gemini_client:
            print("ğŸ”„ Attempting fallback to Google Gemini...")
            try:
                response = self.gemini_client.models.generate_content(
                    model='gemini-2.0-flash',
                    contents=prompt
                )
                return response.text.strip()
            except Exception as e:
                print(f"âš ï¸ Gemini request failed: {e}")
        else:
            print("âš ï¸ Fallback skipped: Google Gemini client is not initialized.")
        
        return "" # Both failed

    def generate_xai_feedback(self, resume_input: dict, recommendations: List[Dict]) -> str:
        """
        ì „ë¬¸ì ì´ê³  ê°ê´€ì ì¸ AI í”¼ë“œë°± ìƒì„± (LLM Enhancement)
        - Rule-based ì´ˆì•ˆ ìƒì„± í›„ LLMìœ¼ë¡œ ì„¸ë ¨ë˜ê²Œ ë‹¤ë“¬ê¸°
        """
        feedback_lines = ["\nì¢…í•© AI ì½”ì¹˜ ì˜ê²¬:"]

        if not recommendations:
            feedback_lines.append("ë¶„ì„ ê²°ê³¼, í˜„ì¬ ì´ë ¥ì„œì— ë¶€í•©í•˜ëŠ” ì¶”ì²œ ê¸°ì—…ì„ ì‹ë³„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ë ¥ì„œì˜ ê¸°ìˆ  ìŠ¤íƒ ë° ê²½ë ¥ ê¸°ìˆ ì„ ì¬ì ê²€í•˜ì—¬ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.")
            return "\n".join(feedback_lines)

        # 1. ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ (ìƒëµ)
        top_rec = recommendations[0]
        top_company_name = top_rec.get('metadata', {}).get('company_name') or top_rec.get('company_name', 'ì¶”ì²œ ê¸°ì—…')
        top_score = top_rec['match_score']
        top_note = top_rec.get('match_type', 'Good Fit')
        
        classification = resume_input.get('classification', {})
        predicted_role = classification.get('predicted_role') or resume_input.get('target_role', 'ë¯¸ì§€ì • ì§ë¬´')
        
        content = resume_input.get('resume_content', {})
        skills_data = content.get('skills', {})
        resume_all_skills = set()
        if isinstance(skills_data, dict):
             resume_all_skills = set(skills_data.get('essential', [])).union(set(skills_data.get('additional', [])))

        experiences = content.get('professional_experience', [])
        projects = content.get('project_experience', [])

        # 2. Rule-based ì´ˆì•ˆ ìƒì„±
        draft_lines = []
        
        # ê¸°ìˆ  ì—­ëŸ‰ ë¶„ì„ (Raw Logic)
        tech_match_pct = int(top_rec.get('keyword_raw', 0) * 100)
        skills_list = list(resume_all_skills)
        draft_lines.append(f"ê¸°ìˆ  ì¼ì¹˜ë„: {tech_match_pct}%")
        
        # ì‹¤ë¬´ ê²½í—˜ ë¶„ì„
        draft_lines.append(f"ê²½ë ¥: {len(experiences)}ê±´")
        
        # ì§ë¬´ ì—°ê´€ì„±
        relevance_pct = int(top_rec.get('vector_norm', 0) * 100)
        draft_lines.append(f"ì§ë¬´ ì—°ê´€ì„±: {relevance_pct}%")
        
        # 3. LLMì—ê²Œ ë‹¤ë“¬ê¸° ìš”ì²­
        context = "\n".join(draft_lines)
        prompt = f"""
        ì§€ì›ì ì •ë³´: {context}
        ì¶”ì²œ ê¸°ì—…: {top_company_name} ({top_score}ì )
        ì§ë¬´: {predicted_role}

        ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì§€ì›ìì—ê²Œ í•´ì¤„ ìˆ˜ ìˆëŠ” 'ì¢…í•© í”¼ë“œë°±'ì„ 3~4ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ì¤˜.
        1. ê¸°ìˆ  ì—­ëŸ‰ì— ëŒ€í•œ ê°ê´€ì  í‰ê°€
        2. ê°•ì ê³¼ ë³´ì™„ì 
        3. ê²©ë ¤ ë° ì¡°ì–¸
        ë§íˆ¬ëŠ” "ì „ë¬¸ ì»¨ì„¤í„´íŠ¸"ì²˜ëŸ¼ ì •ì¤‘í•˜ê²Œ í•´ì¤˜.
        """
        
        llm_feedback = self._ask_llm(prompt)
        
        if llm_feedback:
             return f"\nì¢…í•© AI ì½”ì¹˜ ì˜ê²¬:\n{llm_feedback}"
        else:
             # Fallback to rule-based logic (if LLM fails)
             return self._generate_rule_based_feedback(resume_input, recommendations)



    # ==========================================
    # ë©”ì¸ ë©”ì†Œë“œ (FastAPI í˜¸í™˜)
    # ==========================================
    def recommend(self, resume_input: dict) -> Tuple[List[Dict], str]:
        """FastAPI ë¼ìš°í„° í˜¸í™˜ìš© ë©”ì¸ ë©”ì†Œë“œ"""
        # [ë°©ì–´ ì½”ë“œ] ê¸°ì—… ë°ì´í„° í™•ì¸
        if not self.companies or self.company_vectors is None:
            return [], "ì‹œìŠ¤í…œ ì—ëŸ¬: ê¸°ì—… ë°ì´í„°(Vector DB)ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

        # 1. ì´ë ¥ì„œ í…ìŠ¤íŠ¸ ë³€í™˜
        resume_text = self._convert_resume_to_text(resume_input)
        
        # 2. ì§ë¬´ íŒŒì•…
        classification = resume_input.get('classification', {})
        role = classification.get('predicted_role') or resume_input.get('target_role', 'backend')

        # 3. ë²¡í„° ì„ë² ë”© ë° ìœ ì‚¬ë„ ê³„ì‚°
        if self.model:
            query_vector = self.model.encode([resume_text])[0]
            vector_scores = cosine_similarity([query_vector], self.company_vectors)[0]
        else:
            vector_scores = [0.0] * len(self.companies)

        # 4. ë²„í‚·íŒ… ë° ì ìˆ˜ ê³„ì‚° (Main Scoring)
        buckets = self._categorize_companies(self.companies, vector_scores, resume_input, role)

        # 5. ë“±ê¸‰ ê¸°ë°˜ ê¸°ì—… ì„ ì • (Smart Selection)
        all_comp_data = []
        for t in buckets: all_comp_data.extend(buckets[t])
        
        # ê°•ì œ Fë“±ê¸‰ ì—¬ë¶€ í™•ì¸
        is_candidate_forced_f = any(c.get('is_forced_f', False) for c in all_comp_data)
        
        resume_evaluation = resume_input.get('evaluation') or {}
        candidate_grade = resume_evaluation.get('grade')
        
        if is_candidate_forced_f:
            candidate_grade = "F"
        elif candidate_grade is None:
            if all_comp_data:
                # ìƒìœ„ 3ê°œ í‰ê· ìœ¼ë¡œ ìë™ ë“±ê¸‰ ì‚°ì •
                sorted_companies = sorted(all_comp_data, key=lambda x: x['raw_score'], reverse=True)
                top_scores = [c['raw_score'] for c in sorted_companies[:3]]
                avg_score = sum(top_scores) / len(top_scores) if top_scores else 0.0
                candidate_grade = self.get_grade(avg_score)
            else:
                candidate_grade = "B"
        elif candidate_grade == "F":
            # Ghost F Recovery (êµ¬ì œ ë¡œì§)
            all_raw = [c['raw_score'] for c in all_comp_data]
            if all_raw and (sum(all_raw)/len(all_raw)) > 60:
                candidate_grade = "C"

        # íƒ€ê²Ÿ í‹°ì–´ ì„ ì •
        target_slots = self.TIER_RULES.get(candidate_grade, self.TIER_RULES["B"])
        final_selection = []
        used_companies = set()

        for required_tier in target_slots:
            selected = None
            for comp in buckets.get(required_tier, []):
                if comp['metadata']['company_name'] not in used_companies:
                    selected = comp
                    break
            
            # Fallback (í•´ë‹¹ í‹°ì–´ì— ì—†ìœ¼ë©´ ë‹¤ë¥¸ í‹°ì–´ ê²€ìƒ‰)
            if not selected:
                order = ["Top", "Mid", "Low"] if required_tier == "Top" else ["Mid", "Low", "Top"]
                for tier in order:
                    for comp in buckets.get(tier, []):
                        if comp['metadata']['company_name'] not in used_companies:
                            selected = comp
                            break
                    if selected: break
            
            if selected:
                used_companies.add(selected['metadata']['company_name'])
                final_selection.append(selected)

        # 6. ì ìˆ˜ ë§¤í•‘ ë° í¬ë§·íŒ…
        formatted_results = [] # ì‘ë‹µìš© (Slim)
        full_data_results = [] # ë‚´ë¶€ìš© (Full)

        for i, res in enumerate(final_selection):
            # Dynamic Scaling
            if i < len(self.SCORE_RANGES):
                min_s, max_s = self.SCORE_RANGES[i]
                final_score = self._map_score_to_range(res['raw_score'], min_s, max_s)
            else:
                final_score = round(res['raw_score'], 1)

            if i == 0:
                note = "Best Match"
                match_level = "BEST"
            elif res['raw_score'] < self.GAP_THRESHOLD_RATIO:
                note = "Skill Gap"
                match_level = "GAP"
            else:
                note = "High Fit"
                match_level = "HIGH"

            # ATS ìƒì„¸ ì •ë³´ ì—­ì‚° (Full ë°ì´í„°ìš©)
            ats_data = self._calculate_ats_detail(res.get('missing_skills', []), res.get('tech_stack', []))

            # 1. ë‚´ë¶€ìš© Full Data (í”¼ë“œë°± ìƒì„±ì— í•„ìš”)
            full_entry = {
                "metadata": res['metadata'],
                "company_name": res['metadata']['company_name'],
                "match_score": final_score,
                "tier": res['metadata']['tier'],
                "match_type": note,
                "match_level": match_level,
                "reason": f"Tech Match: {res['keyword_raw']*100:.0f}%, Vector: {res['vector_norm']:.2f}",
                "raw_score": final_score,
                "is_exact_match": (note == "Best Match") or (final_score >= 85),
                "tech_stack": res['tech_stack'],
                "missing_skills": res.get('missing_skills', []),
                "note": note,
                "keyword_raw": res['keyword_raw'],
                "vector_norm": res['vector_norm'],
                "ats_score": ats_data
            }
            full_data_results.append(full_entry)

            # 2. ì‘ë‹µìš© Slim Data (7ê°œ í•„ë“œ ì œê±°ë¨)
            slim_entry = {
                "company_name": res['metadata']['company_name'],
                "match_score": final_score,
                "tier": res['metadata']['tier'],
                "match_type": note,
                "match_level": match_level,
                "missing_skills": res.get('missing_skills', []),
                "note": note,
                "is_exact_match": (note == "Best Match") or (final_score >= 85)
            }
            formatted_results.append(slim_entry)

        # 7. AI í”¼ë“œë°± ìƒì„± (Full Data ì‚¬ìš©!)
        report = self.generate_xai_feedback(resume_input, full_data_results)

        # [ìˆ˜ì •] formatted_results ëŒ€ì‹  full_data_resultsë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        # ì´ìœ : main.pyê°€ tech_stack, reason ë“±ì„ í•„ìˆ˜ í•„ë“œë¡œ ìš”êµ¬í•˜ê¸° ë•Œë¬¸ì—
        # formatted_resultsë¥¼ ë³´ë‚´ë©´ 500 ì—ëŸ¬ê°€ ë°œìƒí•©ë‹ˆë‹¤.
        # í™”ë©´ì—ë„ Tech Stackì„ ë³´ì—¬ì£¼ë ¤ë©´ Full Dataê°€ í•„ìš”í•©ë‹ˆë‹¤.
        return full_data_results, report

if __name__ == "__main__":
    engine = MatchingEngine()
    print("Engine Fully Initialized with All Features.")