import os
import json
import numpy as np
from typing import List, Dict, Any, Tuple, Optional
from pathlib import Path
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

try:
    from sentence_transformers import SentenceTransformer
    from sklearn.metrics.pairwise import cosine_similarity
    from openai import OpenAI
except ImportError:
    SentenceTransformer = None
    OpenAI = None
    cosine_similarity = None
    print("âš ï¸ [Warning] í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬(sentence_transformers, sklearn, openai)ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ì—°ê´€ ì§ë¬´ ê·¸ë£¹ ì •ì˜ (Flexible ì¶”ì²œìš©)
RELATED_ROLES = {
    "ê¸°íš": ["ì„œë¹„ìŠ¤ ê¸°íš", "PO", "PM", "í”„ë¡œë•íŠ¸", "ë§ˆì¼€íŒ…", "ìš´ì˜", "ì „ëµ"],
    "ê°œë°œ": ["Developer", "ê°œë°œì", "ì—”ì§€ë‹ˆì–´", "Engineer", "Fullstack", "Backend", "Frontend"],
    "ë°ì´í„°": ["ë°ì´í„°", "Data", "ML", "AI", "ë¶„ì„", "Analyst"],
    "ë””ìì¸": ["ë””ìì¸", "Design", "UX", "UI", "ë¸Œëœë“œ"],
}

class MatchingEngine:
    """
    [Hybrid RAG Engine]
    ë²¡í„° ê²€ìƒ‰(S-BERT) + í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ë§ + AI ë¦¬í¬íŠ¸(GPT)
    """
    
    def __init__(self, base_path: Optional[str] = None, openai_api_key: Optional[str] = None):
        print("ğŸš€ ë§¤ì¹­ ì—”ì§„(Matching Engine) ì´ˆê¸°í™” ì¤‘...")
        
        # ê²½ë¡œ ìë™ ì„¤ì • (app/services/matching_engine.py -> project_root/data)
        if base_path is None:
            current_dir = Path(__file__).resolve().parent
            self.base_path = current_dir.parent.parent / "data"
        else:
            self.base_path = Path(base_path)

        # ëª¨ë“  ì†ì„± ì‚¬ì „ ì´ˆê¸°í™”
        self.model = None
        self.company_vectors = None
        self.company_metadata = []
        self.client = None
        
        # 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì²´í¬
        if not SentenceTransformer:
            print("âš ï¸ [Critical] sentence_transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # 2. OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
        api_key = openai_api_key or os.getenv("OPENAI_API_KEY")
        self.client = OpenAI(api_key=api_key) if api_key else None
        if not self.client:
            print("âš ï¸ [Warning] OpenAI API Keyê°€ ì—†ìŠµë‹ˆë‹¤. AI ë¦¬í¬íŠ¸ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")
        
        # 3. ë°ì´í„° ë° ëª¨ë¸ ë¡œë“œ
        try:
            print(f"ğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘... ({self.base_path})")
            
            # (1) ë²¡í„° ë°ì´í„° ë¡œë“œ (.npy)
            vector_path = self.base_path / "final_embedded_dataset_600.npy"
            if vector_path.exists():
                self.company_vectors = np.load(vector_path)
                print(f"  - ë²¡í„° ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {self.company_vectors.shape}")
            else:
                print(f"âŒ ë²¡í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {vector_path}")
                print("ğŸ‘‰ 'final_embedded_dataset_600.npy' íŒŒì¼ì´ data í´ë”ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
                self.company_vectors = None

            # (2) ë©”íƒ€ë°ì´í„° ë¡œë“œ (.json)
            # engineìš© ë©”íƒ€ë°ì´í„°ê°€ ë”°ë¡œ ìˆë‹¤ë©´ ê·¸ê±¸ ì“°ê³ , ì—†ë‹¤ë©´ pool ì‚¬ìš©
            meta_path = self.base_path / "final_metadata_600.json"
            # ë§Œì•½ final_metadata.jsonì´ ì—†ìœ¼ë©´ company_50_pool.jsonì„ ëŒ€ì²´ ì‚¬ìš© ì‹œë„
            if not meta_path.exists():
                meta_path = self.base_path / "company_50_pool.json"

            if meta_path.exists():
                with open(meta_path, 'r', encoding='utf-8') as f:
                    self.company_metadata = json.load(f)
                print(f"  - ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.company_metadata)}ê°œ")
            else:
                print(f"âŒ ë©”íƒ€ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {meta_path}")
                self.company_metadata = []

            # (3) ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
            print("ğŸ§  ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘ (jhgan/ko-sroberta-multitask)...")
            # ë¡œì»¬ ìºì‹œê°€ ìˆìœ¼ë©´ ë¹ ë¥´ì§€ë§Œ, ì²˜ìŒì—” ë‹¤ìš´ë¡œë“œ ì‹œê°„ ì†Œìš”ë¨
            self.model = SentenceTransformer('jhgan/ko-sroberta-multitask')
            print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

        except Exception as e:
            print(f"âŒ ì´ˆê¸°í™” ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
            self.model = None
            self.company_vectors = None
            self.company_metadata = []

    def recommend(self, resume_data: Dict[str, Any]) -> Tuple[List[Dict], str]:
        """
        ì´ë ¥ì„œ ë°ì´í„°ë¥¼ ë°›ì•„ ì¶”ì²œ ê¸°ì—… ë¦¬ìŠ¤íŠ¸ì™€ AI ë¦¬í¬íŠ¸ë¥¼ ë°˜í™˜
        ê·œì¹™: 1, 2ìœ„ëŠ” Target Role ì¼ì¹˜(Exact), 3ìœ„ëŠ” ìœ ì—°í•œ ì¶”ì²œ(Flexible)
        """
        if not self.model or self.company_vectors is None or not self.company_metadata:
            return [], "âš ï¸ ë§¤ì¹­ ì—”ì§„ì´ ì •ìƒì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (ë°ì´í„° ëˆ„ë½ ë“±)."

        # 1. ì´ë ¥ì„œ ì •ë³´ ì¶”ì¶œ
        resume_content = resume_data.get('resume_content', {})
        target_role = resume_data.get('target_role', '').lower()
        
        # Pydantic ëª¨ë¸ì—ì„œ dictë¡œ ë³€í™˜ë˜ì–´ ë“¤ì–´ì˜¬ ë•Œ í•„ë“œ ì ‘ê·¼ ì²˜ë¦¬
        if hasattr(resume_content, 'dict'): resume_content = resume_content.dict()
        
        eval_data = resume_data.get('resume_evaluation', {}) or {}
        if hasattr(eval_data, 'dict'): eval_data = eval_data.dict()

        # classification ì •ë³´ê°€ ì—†ìœ¼ë©´ ì„ì‹œ ìƒì„± (Resume ìŠ¤í‚¤ë§ˆì— classificationì´ ì—†ìœ¼ë¯€ë¡œ)
        classification = {
            'keywords': resume_content.get('skills', {}).get('essential', []) + 
                        resume_content.get('skills', {}).get('additional', []),
            'predicted_role': target_role
        }
        
        resume_keywords = set([k.lower() for k in classification.get('keywords', [])])
        
        # 2. ê°œì„ ëœ ì¿¼ë¦¬ í…ìŠ¤íŠ¸ ìƒì„±
        query_text = self._build_query_text(target_role, classification, eval_data)
        query_vector = self.model.encode(query_text)

        # 3. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        # ë²¡í„° í¬ê¸° ë¶ˆì¼ì¹˜ ë°©ì§€
        if query_vector.shape[0] != self.company_vectors.shape[1]:
             print(f"âš ï¸ ë²¡í„° ì°¨ì› ë¶ˆì¼ì¹˜! Query: {query_vector.shape}, DB: {self.company_vectors.shape}")
             return [], "ì„ë² ë”© ëª¨ë¸ ë²„ì „ì´ ë°ì´í„° ìƒì„± ì‹œì ê³¼ ë‹¤ë¦…ë‹ˆë‹¤."

        raw_scores = cosine_similarity([query_vector], self.company_vectors)[0]

        # 4. Top N í›„ë³´êµ° ì¶”ì¶œ (ë„‰ë„‰í•˜ê²Œ 30ê°œ)
        top_n_indices = np.argsort(raw_scores)[::-1][:30]
        
        # 5. í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ë§ ì ìš©
        candidates = []
        for idx in top_n_indices:
            # ì¸ë±ìŠ¤ ë²”ìœ„ ì²´í¬
            if idx >= len(self.company_metadata): continue
                
            company = self.company_metadata[idx]
            cosine_score = float(raw_scores[idx])
            
            # ì§ë¬´ ì¼ì¹˜ ì—¬ë¶€ í™•ì¸
            # company_pool.jsonì—ëŠ” job_titleì´ ì—†ì„ ìˆ˜ ìˆìŒ -> target_rolesë¡œ ëŒ€ì²´
            if 'job_title' in company:
                job_title = company.get('job_title', '').lower()
            else:
                # target_roles ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ í•©ì³ì„œ ë¹„êµ
                job_title = " ".join(company.get('target_roles', [])).lower()

            is_exact_match = self._check_exact_match(target_role, job_title)
            is_related_role = self._check_related_role(target_role, job_title)
            
            # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚°
            hybrid_score = self._calculate_hybrid_score(
                cosine_score=cosine_score,
                is_exact_match=is_exact_match,
                resume_keywords=resume_keywords,
                company=company
            )
            
            candidates.append({
                "metadata": company,
                "raw_score": hybrid_score,
                "cosine_score": cosine_score * 100,
                "is_exact_match": is_exact_match,
                "is_related_role": is_related_role
            })

        # 6. ì ìˆ˜ ì •ê·œí™” (ìƒìœ„ í›„ë³´ ê¸°ì¤€)
        candidates = self._normalize_scores(candidates)

        # 7. í•„í„°ë§ ë¡œì§ (1,2ìœ„ Exact / 3ìœ„ Flexible)
        final_recommendations = self._apply_filtering_rules(candidates, target_role)

        # 8. AI ë¦¬í¬íŠ¸ ìƒì„±
        ai_report = self._generate_ai_report(resume_data, final_recommendations)
        
        return final_recommendations, ai_report

    def _build_query_text(self, target_role: str, classification: Dict, eval_data: Dict) -> str:
        parts = []
        if target_role:
            parts.append(target_role)
            parts.append(target_role)
        
        predicted_role = classification.get('predicted_role', '')
        if predicted_role: parts.append(predicted_role)
        
        keywords = classification.get('keywords', [])
        if keywords:
            parts.extend(keywords)
            parts.extend(keywords)
        
        # eval_data êµ¬ì¡° ëŒ€ì‘ (ResumeEvaluation ê°ì²´ì¼ ìˆ˜ ìˆìŒ)
        if isinstance(eval_data, dict):
             # summaryê°€ ë¬¸ìì—´ì´ê±°ë‚˜ dictì¼ ìˆ˜ ìˆìŒ
             summary = eval_data.get('reasoning') or eval_data.get('summary') or ''
        else:
             summary = ''

        if summary: parts.append(str(summary))
        
        return " ".join(parts)

    def _check_exact_match(self, target_role: str, job_title: str) -> bool:
        if not target_role: return False
        if target_role in job_title: return True
        pm_keywords = ['pm', 'po', 'ê¸°íš', 'product', 'í”„ë¡œë•íŠ¸']
        if any(kw in target_role for kw in pm_keywords):
            if any(kw in job_title for kw in pm_keywords): return True
        return False

    def _check_related_role(self, target_role: str, job_title: str) -> bool:
        if not target_role: return False
        target_group = None
        for group, keywords in RELATED_ROLES.items():
            if any(kw.lower() in target_role for kw in keywords):
                target_group = group
                break
        if not target_group: return False
        for kw in RELATED_ROLES[target_group]:
            if kw.lower() in job_title: return True
        return False

    def _calculate_hybrid_score(self, cosine_score: float, is_exact_match: bool, resume_keywords: set, company: Dict) -> float:
        base_score = cosine_score * 60
        role_bonus = 20 if is_exact_match else 0
        
        company_stack = company.get('tech_stack', [])
        company_skills = set(s.lower() for s in company_stack)
        
        if resume_keywords and company_skills:
            matching_count = len(resume_keywords & company_skills)
            total_keywords = len(resume_keywords)
            keyword_score = (matching_count / max(total_keywords, 1)) * 20
        else:
            keyword_score = 0
        
        return base_score + role_bonus + keyword_score

    def _normalize_scores(self, candidates: List[Dict]) -> List[Dict]:
        if not candidates: return candidates
        max_score = max(c['raw_score'] for c in candidates)
        min_score = min(c['raw_score'] for c in candidates)
        
        if max_score == min_score:
            for c in candidates: c['raw_score'] = 85.0
            return candidates
        
        for c in candidates:
            normalized = 60 + (c['raw_score'] - min_score) / (max_score - min_score) * 35
            c['raw_score'] = round(normalized, 1)
        return candidates

    def _apply_filtering_rules(self, candidates: List[Dict], target_role: str = "") -> List[Dict]:
        exact_matches = [c for c in candidates if c['is_exact_match']]
        related_matches = [c for c in candidates if not c['is_exact_match'] and c.get('is_related_role', False)]
        other_matches = [c for c in candidates if not c['is_exact_match'] and not c.get('is_related_role', False)]
        
        flexible_matches = [c for c in related_matches if c['raw_score'] >= 65]
        flexible_matches.extend([c for c in other_matches if c['raw_score'] >= 65])
        
        if not flexible_matches:
            flexible_matches = related_matches + other_matches
        
        result = []
        # 1, 2ìœ„ Exact ìš°ì„ 
        for _ in range(2):
            if exact_matches: result.append(exact_matches.pop(0))
            elif flexible_matches: result.append(flexible_matches.pop(0))
        # 3ìœ„ Flexible ìš°ì„ 
        if flexible_matches: result.append(flexible_matches.pop(0))
        elif exact_matches: result.append(exact_matches.pop(0))
            
        return result[:3]

    def _generate_ai_report(self, resume_data: Dict, recommendations: List[Dict]) -> str:
        if not self.client:
            return "OpenAI API Key ë¯¸ì„¤ì •ìœ¼ë¡œ AI ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        try:
            target_role = resume_data.get('target_role', 'ì§€ì› ì§ë¬´')
            summary = resume_data.get('resume_evaluation', {}).get('reasoning', 'ì´ë ¥ì„œ ìš”ì•½ ì—†ìŒ')
            
            company_names = []
            for i, rec in enumerate(recommendations):
                c_name = rec['metadata'].get('company_name') or rec['metadata'].get('name')
                c_job = rec['metadata'].get('job_title') or " ".join(rec['metadata'].get('target_roles', []))
                company_names.append(f"{i+1}. {c_name} ({c_job})")
            
            company_text = "\n".join(company_names)
            prompt = f"""
            [ì§€ì›ì] ì§ë¬´: {target_role}, ìš”ì•½: {summary}
            [ì¶”ì²œê¸°ì—…] {company_text}
            ìœ„ ì§€ì›ìì—ê²Œ ì¶”ì²œ ê¸°ì—…ì´ ì™œ ì í•©í•œì§€, íŠ¹íˆ 3ë²ˆì§¸ ê¸°ì—…ì€ ì–´ë–¤ ì°¨ë³„ì ì´ ìˆëŠ”ì§€ 3ë¬¸ì¥ìœ¼ë¡œ ê²©ë ¤í•˜ë©° ìš”ì•½í•´ì¤˜.
            """
            
            response = self.client.chat.completions.create(
                model="gpt-4o-mini", 
                messages=[{"role": "user", "content": prompt}],
                max_tokens=300
            )
            return response.choices[0].message.content or ""
        except Exception as e:
            return f"AI ë¦¬í¬íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}"