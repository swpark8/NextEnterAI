import uvicorn
import json
from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.exceptions import RequestValidationError
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field, ValidationError
from typing import List, Dict, Any, Optional, Union

# [í•µì‹¬] ìš°ë¦¬ê°€ ë§Œë“  ì—”ì§„ ì„í¬íŠ¸
# (íŒŒì¼ëª…ì´ resume_engine.py ë¼ê³  ê°€ì •)
from app.services.resume_engine import MatchingEngine
from app.services.interview_engine import InterviewEngine
from app.services.file_parser import FileParser  # âœ… Import FileParser

# ==========================================
# 1. FastAPI ì•± ì„¤ì •
# ==========================================
app = FastAPI(
    title="NextEnter AI Resume Analysis Server",
    description="ì´ë ¥ì„œ í‰ê°€ ë° ê¸°ì—… ì¶”ì²œ AI ì—”ì§„ API",
    version="2.3.0 (File Parser Integrated)"
)

# CORS ì„¤ì • (React í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™ìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ëª¨ë“  ë„ë©”ì¸ í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==========================================
# 2. ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ ë° ì„¸ì…˜ ê´€ë¦¬
# ==========================================

# Resume Engine ì´ˆê¸°í™”
engine = MatchingEngine()

# Interview Engine ì„¸ì…˜ ê´€ë¦¬ (ë©”ëª¨ë¦¬ ê¸°ë°˜)
interview_engines: Dict[str, InterviewEngine] = {}

def get_interview_engine(user_id: str) -> InterviewEngine:
    """ì‚¬ìš©ìë³„ ë©´ì ‘ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì„¸ì…˜ ê´€ë¦¬)"""
    if user_id not in interview_engines:
        interview_engines[user_id] = InterviewEngine()
    return interview_engines[user_id]

# ==========================================
# 3. ë°ì´í„° ëª¨ë¸ ì •ì˜ (ìœ ì—°í•œ êµ¬ì¡° ì ìš©)
# ==========================================

# (1) ìš”ì²­ ë°ì´í„° - [ìˆ˜ì •ë¨] ì•„ì£¼ ê´€ëŒ€í•œ ëª¨ë¸ (Hybrid Request)
# í”„ë¡ íŠ¸ì—”ë“œê°€ ì–´ë–¤ í˜•ì‹ìœ¼ë¡œ ë³´ë‚´ë“  ì¼ë‹¨ ë°›ì•„ì„œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
class ResumeRequest(BaseModel):
    id: Optional[str] = "USER_TEMP"
    
    # 1. í•„ìˆ˜ì˜€ë˜ í•„ë“œë“¤ì„ Optionalë¡œ ë³€ê²½ (422 ì—ëŸ¬ ë°©ì§€)
    target_role: Optional[str] = Field(None, description="í¬ë§ ì§ë¬´")
    
    # 2. ì‹ ê·œ êµ¬ì¡° (Nested)
    resume_content: Optional[Dict[str, Any]] = None
    raw_text: Optional[str] = None
    file_path: Optional[str] = None  # âœ… íŒŒì¼ ê²½ë¡œ í•„ë“œ ì¶”ê°€
    
    # 3. êµ¬í˜• êµ¬ì¡° (Flat) - ë‚±ê°œë¡œ ë“¤ì–´ì˜¬ ê²½ìš°ë¥¼ ëŒ€ë¹„
    education: Optional[List[Any]] = None
    skills: Optional[Any] = None # Dict or List
    professional_experience: Optional[List[Any]] = None
    project_experience: Optional[List[Any]] = None
    
    # 4. Java ë°±ì—”ë“œ ì—°ë™ (ë“±ê¸‰/ë¶„ë¥˜)
    classification: Optional[Dict[str, Any]] = None
    evaluation: Optional[Dict[str, Any]] = None
    
    # ê·¸ ì™¸ ì–´ë–¤ í•„ë“œê°€ ë“¤ì–´ì™€ë„ ì—ëŸ¬ë‚´ì§€ ì•ŠìŒ
    class Config:
        extra = "ignore" 

# Interview ìš”ì²­ ëª¨ë¸
class InterviewRequest(BaseModel):
    id: Optional[str] = "USER_TEMP"
    target_role: Optional[str] = None
    resume_content: Optional[Dict[str, Any]] = None
    last_answer: Optional[str] = None
    portfolio: Optional[Dict[str, Any]] = None
    portfolio_files: Optional[List[str]] = None
    classification: Optional[Dict[str, Any]] = None
    evaluation: Optional[Dict[str, Any]] = None
    education: Optional[List[Any]] = None
    skills: Optional[Any] = None
    professional_experience: Optional[List[Any]] = None
    project_experience: Optional[List[Any]] = None
    total_turns: Optional[int] = 5  # âœ… ì „ì²´ ë©´ì ‘ ì§ˆë¬¸ íšŸìˆ˜ ì¶”ê°€
    
    # [NEW] Stateless Context Support
    chat_history: Optional[List[Dict[str, Any]]] = None # ì´ì „ ëŒ€í™” ë‚´ìš© (Stateless ì§€ì›)
    difficulty: Optional[str] = "JUNIOR" # JUNIOR | SENIOR
    
    class Config:
        extra = "ignore"

# Interview ì‘ë‹µ ëª¨ë¸
class InterviewResponse(BaseModel):
    status: str
    resume_id: str
    target_role: str
    realtime: Dict[str, Any]

# Analysis ì‘ë‹µ ëª¨ë¸
class AnalysisResponse(BaseModel):
    status: str
    resume_id: str
    target_role: str
    grade: str
    score: float
    ai_feedback: Any
    recommendations: List[Any]

@app.post("/api/v1/analyze", response_model=AnalysisResponse)
async def analyze_resume(request: Union[Request, ResumeRequest]):
    """
    ì´ë ¥ì„œ ë¶„ì„ ë° AI ê¸°ì—… ë§¤ì¹­. Request(ì§ì ‘ í˜¸ì¶œ) ë˜ëŠ” ResumeRequest(/recommend ê²½ìœ ) ëª¨ë‘ ì²˜ë¦¬.
    """
    try:
        # 1. ì¸ì ë¶„ê¸°: Requestë©´ body íŒŒì‹±, ResumeRequestë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        if isinstance(request, Request):
            raw_body = await request.body()
            print(f"ğŸ” [Raw Body] {raw_body.decode('utf-8')}")
            body_dict = await request.json()
            print(f"ğŸ” [Parsed JSON] {json.dumps(body_dict, indent=2, ensure_ascii=False)}")
            request_obj = ResumeRequest(**body_dict)
            print(f"ğŸ” [Pydantic Model] {request_obj}")
        else:
            request_obj = request  # /recommendì—ì„œ ë„˜ì–´ì˜¨ ResumeRequest
            print(f"ğŸ” [Parsed] ResumeRequest (from /recommend)")

        # âœ… [New] íŒŒì¼ íŒŒì‹± ë¡œì§ ì¶”ê°€ (ì´ë ¥ì„œ íŒŒì¼ì´ ìˆìœ¼ë©´ í…ìŠ¤íŠ¸ ì¶”ì¶œ)
        if request_obj.file_path:
            print(f"ğŸ“‚ Parsing resume file from: {request_obj.file_path}")
            extracted_text = FileParser.parse_file(request_obj.file_path)
            
            if extracted_text and not extracted_text.startswith("[Error]"):
                print(f"âœ… Extracted {len(extracted_text)} chars from file.")
                # raw_textì— ì¶”ê°€ (ê¸°ì¡´ í…ìŠ¤íŠ¸ê°€ ìˆë‹¤ë©´ ë³‘í•©)
                existing_text = request_obj.raw_text or ""
                request_obj.raw_text = existing_text + "\n\n[Parsed File Content]\n" + extracted_text
            else:
                print(f"âš ï¸ File parsing failed or file empty: {extracted_text}")
        
        final_target_role = request_obj.target_role
        if not final_target_role:
            print("âš ï¸ 'target_role'ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ 'backend'ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
            final_target_role = "backend"

        final_content = request_obj.resume_content
        if not final_content:
            print("âš ï¸ 'resume_content' (í¬ì¥ ìƒì)ê°€ ì—†ìŠµë‹ˆë‹¤. ë‚±ê°œ ë°ì´í„°ë¥¼ ì¡°ë¦½í•©ë‹ˆë‹¤.")
            final_content = {
                "raw_text": request_obj.raw_text,
                "education": request_obj.education or [],
                "skills": request_obj.skills or {},
                "professional_experience": request_obj.professional_experience or [],
                "project_experience": request_obj.project_experience or []
            }
        else:
            # resume_contentê°€ ì´ë¯¸ ìˆì§€ë§Œ, raw_text ê°€ ì—…ë°ì´íŠ¸ ë˜ì—ˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë™ê¸°í™”
            if request_obj.raw_text:
                if "raw_text" in final_content:
                    final_content["raw_text"] += "\n\n" + request_obj.raw_text
                else:
                    final_content["raw_text"] = request_obj.raw_text
        
        resume_input = {
            "id": request_obj.id,
            "target_role": final_target_role,
            "resume_content": final_content,
            "classification": (request_obj.classification or {}),
            "evaluation": (request_obj.evaluation or {})
        }
        
        print(f"ğŸ” Analyzing for role: {final_target_role}")

        if engine:
            results, report = engine.recommend(resume_input)
        else:
            raise Exception("Engine not initialized")
        
        if not results:
            print("âš ï¸ No recommendations generated.")
            grade = "F"
            top_score = 0.0
        else:
            top_score = results[0]['match_score']
            
            # [FIX] Javaì—ì„œ ë°›ì€ ë“±ê¸‰ ì •ë³´ ìš°ì„  ì‚¬ìš©
            evaluation = resume_input.get('evaluation', {})
            grade = evaluation.get('grade')
            
            if grade:
                print(f"âœ… [ë“±ê¸‰ ì •ë³´] Javaì—ì„œ ë°›ì€ ë“±ê¸‰ ì‚¬ìš©: {grade}")
            else:
                # ë“±ê¸‰ ì •ë³´ê°€ ì—†ìœ¼ë©´ ìë™ ê³„ì‚°
                grade = engine.get_grade(top_score)
                print(f"âš ï¸ [ë“±ê¸‰ ì •ë³´] ìë™ ê³„ì‚°ëœ ë“±ê¸‰ ì‚¬ìš©: {grade}")

        response = {
            "status": "success",
            "resume_id": request_obj.id,
            "target_role": final_target_role,
            "grade": grade,
            "score": top_score,
            "ai_feedback": report,
            "recommendations": results
        }
        
        print(f"ğŸ“¤ [Response] Success! Grade: {grade}, Recs: {len(results)}")
        return response

    except Exception as e:
        import traceback
        traceback.print_exc()
        # print(f"âŒ [Error] {str(e)}") # tracebackì—ì„œ ì¶œë ¥ë¨
        raise HTTPException(status_code=500, detail=f"Server Logic Error: {str(e)}")
    
# [Legacy Alias]
@app.post("/api/v1/recommend", response_model=AnalysisResponse, tags=["Legacy"])
async def recommend_resume_alias(resume_request: ResumeRequest):
    """
    /recommend ìš”ì²­ë„ ìœ„ì™€ ë˜‘ê°™ì´ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    print("ğŸ”„ Redirecting /recommend to /analyze...")
    return await analyze_resume(resume_request)

@app.post("/api/v1/interview/next", response_model=InterviewResponse)
async def interview_next(request: Request):
    try:
        # 1. Robust Body Parsing (Fix for Empty Body / Debugging)
        body_bytes = await request.body()
        if not body_bytes:
             print("âŒ [Error] Received 0 bytes body in /interview/next")
             raise HTTPException(status_code=400, detail="Empty request body received")
        
        try:
            body_json = await request.json()
            print(f"ğŸ” [Interview Request] Raw JSON: {json.dumps(body_json, indent=None, ensure_ascii=False)[:300]}...") 
        except Exception as e:
            # Enhanced error logging for debugging encoding issues
            print(f"âŒ [Error] JSON Parse Failed: {str(e)}")
            try:
                # Try to decode with replacement to show what we received
                print(f"âŒ [Error] Body Preview (lossy): {body_bytes.decode('utf-8', errors='replace')[:500]}")
            except:
                pass
            raise HTTPException(status_code=400, detail=f"Invalid JSON format: {str(e)}")

        # 2. Convert to Pydantic Model manually
        try:
            interview_request = InterviewRequest(**body_json)
        except ValidationError as ve:
            print(f"âŒ [Error] Pydantic Validation Failed: {ve}")
            raise HTTPException(status_code=422, detail=f"Validation Error: {ve}")

        # 3. Core Logic
        print(f"ğŸ” [Interview Logic] id={interview_request.id}, role={interview_request.target_role}")

        final_target_role = interview_request.target_role
        if not final_target_role and interview_request.classification:
            final_target_role = interview_request.classification.get("predicted_role")
        if not final_target_role:
            final_target_role = "backend"

        final_content = interview_request.resume_content
        if not final_content:
            final_content = {
                "education": interview_request.education or [],
                "skills": interview_request.skills or {},
                "professional_experience": interview_request.professional_experience or [],
                "project_experience": interview_request.project_experience or []
            }
        # raw_text fallback: êµ¬ì¡°í™” í•„ë“œê°€ ë¹„ì–´ ìˆìœ¼ë©´ raw_textë¥¼ ìš”ì•½ìš©ìœ¼ë¡œ ìœ ì§€ (ë©´ì ‘ ì—”ì§„ì—ì„œ ì‚¬ìš©)
        if final_content and final_content.get("raw_text"):
            sk = final_content.get("skills")
            skills_nonempty = (
                (isinstance(sk, list) and len(sk) > 0)
                or (isinstance(sk, dict) and (len(sk.get("essential") or []) > 0 or len(sk.get("additional") or []) > 0))
            )
            has_structure = (
                skills_nonempty
                or (isinstance(final_content.get("education"), list) and len(final_content.get("education", [])) > 0)
                or (isinstance(final_content.get("professional_experience"), list) and len(final_content.get("professional_experience", [])) > 0)
                or (isinstance(final_content.get("project_experience"), list) and len(final_content.get("project_experience", [])) > 0)
            )
            if not has_structure:
                final_content["_raw_text_primary"] = True  # ì—”ì§„ì—ì„œ raw_textë¥¼ ìš°ì„  ì‚¬ìš©

        resume_input = {
            "id": interview_request.id,
            "target_role": final_target_role,
            "resume_content": final_content,
            "classification": interview_request.classification or {},
            "evaluation": interview_request.evaluation or {}
        }

        # ì„¸ì…˜ë³„ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ íšë“
        itv_engine = get_interview_engine(interview_request.id)

        realtime = itv_engine.generate_response(
            resume_input,
            interview_request.portfolio,
            interview_request.last_answer,
            interview_request.portfolio_files,
            total_turns=interview_request.total_turns, # âœ… total_turns ì „ë‹¬
            chat_history=interview_request.chat_history, # âœ… [NEW] Chat History ì „ë‹¬
            difficulty=interview_request.difficulty # âœ… [NEW] Difficulty ì „ë‹¬
        )

        response = {
            "status": "success",
            "resume_id": interview_request.id,
            "target_role": final_target_role,
            "realtime": realtime
        }
        print(f"ğŸ“¤ [Interview Response] Success for resume_id={interview_request.id}")
        return response


    except HTTPException:
        raise
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Interview Engine Error: {str(e)}")

class FinalizeRequest(BaseModel):
    id: str
    chat_history: Optional[List[Dict[str, Any]]] = None # [NEW] Stateless ì§€ì›

@app.post("/api/v1/interview/finalize")
async def interview_finalize(request: FinalizeRequest):
    """
    [POST] /api/v1/interview/finalize
    ë©´ì ‘ì„ ì¢…ë£Œí•˜ê³  ìµœì¢… í‰ê°€ ë¦¬í¬íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        print(f"ğŸ Finalizing interview for ID: {request.id}")
        
        # 1. ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ ì¡°íšŒ
        if request.id not in interview_engines:
            raise HTTPException(status_code=404, detail="ì§„í–‰ ì¤‘ì¸ ë©´ì ‘ ì„¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
            
        itv_engine = get_interview_engine(request.id)
        
        # 2. ë¦¬í¬íŠ¸ ìƒì„±
        result = itv_engine.finalize_interview(chat_history=request.chat_history)
        
        if "error" in result:
             raise HTTPException(status_code=400, detail=result["error"])
             
        # 3. ì„¸ì…˜ ì •ë¦¬ (ì„ íƒ ì‚¬í•­: ë¦¬í¬íŠ¸ ìƒì„± í›„ ì„¸ì…˜ì„ ìœ ì§€í• ì§€ ì‚­ì œí• ì§€ ê²°ì •. ì—¬ê¸°ì„œëŠ” ìœ ì§€)
        # del interview_engines[request.id] 
        
        print(f"âœ… Final Report Generated: {result.get('result')}, Score: {result.get('total_score')}")
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ [Error] Finalize failed: {e}")
        raise HTTPException(status_code=500, detail=f"Finalize Error: {str(e)}")

@app.get("/")
async def health_check():
    return {"status": "ok", "message": "NextEnter AI Server is running properly (Hybrid Mode)."}

if __name__ == "__main__":
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)
