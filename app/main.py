import uvicorn
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import List, Dict, Any, Optional

# [í•µì‹¬] ìš°ë¦¬ê°€ ë§Œë“  ì—”ì§„ ì„í¬íŠ¸
# (íŒŒì¼ëª…ì´ resume_engine.py ë¼ê³  ê°€ì •)
from services.resume_engine import MatchingEngine

# ==========================================
# 1. FastAPI ì•± ì„¤ì •
# ==========================================
app = FastAPI(
    title="NextEnter AI Resume Analysis Server",
    description="ì´ë ¥ì„œ í‰ê°€ ë° ê¸°ì—… ì¶”ì²œ AI ì—”ì§„ API",
    version="2.1.0"
)

# CORS ì„¤ì • (React í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™ìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ë³´ì•ˆì„ ìœ„í•´ ë°°í¬ ì‹œì—ëŠ” êµ¬ì²´ì  ë„ë©”ì¸ ê¶Œì¥
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==========================================
# 2. ì—”ì§„ ì´ˆê¸°í™” (ì„œë²„ ì‹œì‘ ì‹œ 1íšŒ ë¡œë“œ)
# ==========================================
print("ğŸš€ Server initializing...")
engine = MatchingEngine()
print("âœ… Server ready to accept requests.")

# ==========================================
# 3. ë°ì´í„° ëª¨ë¸ ì •ì˜ (Pydantic) - Schema í†µí•© ì™„ë£Œ
# ==========================================

# (1) ìš”ì²­ ë°ì´í„° (React -> Python)
# resume.pyì˜ ëª¨ë“  í•„ë“œë¥¼ ìˆ˜ìš©í•˜ë„ë¡ ì„¤ê³„ë¨
class ResumeRequest(BaseModel):
    # í•„ìˆ˜ í•„ë“œ
    id: Optional[str] = "USER_TEMP"
    target_role: str = Field(..., description="í¬ë§ ì§ë¬´ (backend, frontend, pm ë“±)")
    
    # [ë³µêµ¬] resume.pyì— ìˆë˜ ì„ íƒ í•„ë“œë“¤ ì™„ë²½ ì´ì‹
    candidate_id: Optional[str] = None
    standardized_role: Optional[Dict[str, Any]] = None
    
    # [í•µì‹¬ ì „ëµ] í•˜ìœ„ ê°ì²´(Education, Skills ë“±)ë¥¼ Dictë¡œ í†µí•©í•˜ì—¬ 422 ì—ëŸ¬ ì›ì²œ ì°¨ë‹¨
    # ê¸°ì¡´ ResumeContent í´ë˜ìŠ¤ ë‚´ìš©ì„ ì´ Dict ì•ˆì— ëª¨ë‘ ë‹´ìŠµë‹ˆë‹¤.
    resume_content: Dict[str, Any] = Field(..., description="ì´ë ¥ì„œ ìƒì„¸ (í•™ë ¥, ìŠ¤í‚¬, ê²½ë ¥ í¬í•¨)")
    
    # ì¶”ê°€ ë©”íƒ€ë°ì´í„°
    classification: Optional[Dict[str, Any]] = None
    evaluation: Optional[Dict[str, Any]] = None

# (2) ì‘ë‹µ ë°ì´í„° - ì¶”ì²œ ê¸°ì—… ìƒì„¸ ì •ë³´
# resume_engine_fixed.pyê°€ ë±‰ëŠ” ê²°ê³¼ë¬¼ê³¼ 1:1 ë§¤ì¹­
class CompanyRecommendation(BaseModel):
    # ê¸°ë³¸ ì •ë³´
    company_name: str
    match_score: float
    tier: str
    match_type: str
    match_level: str
    reason: str
    tech_stack: List[str]
    missing_skills: List[str]
    
    # ìƒì„¸ ì ìˆ˜ (í”¼ë“œë°± ìƒì„±ìš©)
    keyword_raw: float
    vector_norm: float
    ats_score: Optional[Dict[str, Any]] = None
    
    # [Legacy í˜¸í™˜] ê¸°ì¡´ í”„ë¡ íŠ¸ì—”ë“œ ì½”ë“œ ê¹¨ì§ ë°©ì§€
    raw_score: float
    is_exact_match: bool
    
    # ë©”íƒ€ë°ì´í„° (UI í‘œì‹œìš©)
    metadata: Optional[Dict[str, Any]] = None

# (3) ìµœì¢… API ì‘ë‹µ êµ¬ì¡°
class AnalysisResponse(BaseModel):
    status: str = "success"
    resume_id: str
    target_role: str
    
    # ë¶„ì„ ê²°ê³¼
    grade: str
    score: float
    ai_feedback: str  # XAI ë¦¬í¬íŠ¸
    
    # ì¶”ì²œ ë¦¬ìŠ¤íŠ¸
    recommendations: List[CompanyRecommendation]

# ==========================================
# 4. API ì—”ë“œí¬ì¸íŠ¸
# ==========================================

@app.post("/api/v1/analyze", response_model=AnalysisResponse)
async def analyze_resume(request: ResumeRequest):
    """
    [Main API] ì´ë ¥ì„œë¥¼ ë°›ì•„ ë¶„ì„í•˜ê³  ì¶”ì²œ ê¸°ì—…ê³¼ í”¼ë“œë°±ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        print(f"ğŸ“¥ [Request] Analyzing resume: {request.id} ({request.target_role})")
        
        # 1. ìš”ì²­ ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (ì—”ì§„ ì…ë ¥ìš©)
        # Pydantic ëª¨ë¸ì„ dictë¡œ ë°”ê¾¸ë©´ ì—”ì§„ì´ ì“°ê¸° í¸í•¨
        resume_input = request.model_dump()
        
        # 2. ì—”ì§„ ì‹¤í–‰
        # recommend í•¨ìˆ˜ëŠ” (formatted_results, ai_report_string) íŠœí”Œì„ ë°˜í™˜í•¨
        results, report = engine.recommend(resume_input)
        
        # 3. ë°ì´í„° ê²€ì¦ ë° ì•ˆì „ì¥ì¹˜
        if not results:
            print("âš ï¸ No recommendations generated.")
            grade = "F"
            top_score = 0.0
        else:
            # 1ìœ„ ê¸°ì—… ì ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ ë“±ê¸‰ í‘œì‹œ
            top_score = results[0]['match_score']
            grade = engine.get_grade(top_score)

        # 4. ì‘ë‹µ ìƒì„±
        response = {
            "status": "success",
            "resume_id": request.id,
            "target_role": request.target_role,
            "grade": grade,
            "score": top_score,
            "ai_feedback": report,
            "recommendations": results
        }
        
        print(f"ğŸ“¤ [Response] Success! Grade: {grade}, Recs: {len(results)}")
        return response

    except Exception as e:
        import traceback
        traceback.print_exc()
        print(f"âŒ [Error] {str(e)}")
        # 422 Validation Errorê°€ ì•„ë‹Œ 500 ë‚´ë¶€ ì—ëŸ¬ë¡œ ëª…í™•íˆ ë°˜í™˜
        raise HTTPException(status_code=500, detail=f"Server Logic Error: {str(e)}")
    
# [ì¶”ê°€ë¨] ì‚¬ìš©ì ì•ˆì‹¬ìš© Legacy Alias
@app.post("/api/v1/recommend", response_model=AnalysisResponse, tags=["Legacy"])
async def recommend_resume_alias(request: ResumeRequest):
    """
    [Alias] /api/v1/analyze ì™€ ë™ì¼í•˜ê²Œ ë™ì‘í•©ë‹ˆë‹¤.
    (ê¸°ì¡´ recommend APIë¥¼ ì°¾ëŠ” ì‚¬ìš©ìë¥¼ ìœ„í•œ ë³„ì¹­)
    """
    print("ğŸ”„ Redirecting /recommend to /analyze...")
    return await analyze_resume(request)

@app.get("/")
async def health_check():
    return {"status": "ok", "message": "NextEnter AI Server is running properly."}

# ==========================================
# 5. ì„œë²„ ì‹¤í–‰ (ì§ì ‘ ì‹¤í–‰ ì‹œ)
# ==========================================
if __name__ == "__main__":
    # í¬íŠ¸ 8000ë²ˆì—ì„œ ì‹¤í–‰ (ReactëŠ” ë³´í†µ 3000ë²ˆ)
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)